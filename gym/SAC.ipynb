{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hNA9hN6kvvnc"
   },
   "outputs": [],
   "source": [
    "#please run roscore on terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ESSYYOwkvvne"
   },
   "outputs": [],
   "source": [
    "#please run gazebo world on terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1IGNMZ5Evvne"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 04:36:18.687657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:18.688042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:18.688306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:18.688578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:18.688804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:18.689020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2126 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import gym\n",
    "import argparse\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import gc\n",
    "gc.enable()\n",
    "import rospy\n",
    "import roslib\n",
    "import rospy\n",
    "import rostopic\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "from std_srvs.srv import Empty\n",
    "from gazebo_msgs.srv import SetModelConfiguration\n",
    "from control_msgs.msg import JointControllerState\n",
    "from sensor_msgs.msg import JointState\n",
    "from gazebo_msgs.msg import LinkStates\n",
    "from gazebo_msgs.msg import ContactsState\n",
    "from geometry_msgs.msg import Pose\n",
    "from std_msgs.msg import Float64\n",
    "from std_msgs.msg import String\n",
    "from sensor_msgs.msg import Joy\n",
    "from gazebo_msgs.srv import DeleteModel\n",
    "from gazebo_msgs.srv import SpawnModel\n",
    "from controller_manager_msgs.srv import LoadController\n",
    "from controller_manager_msgs.srv import SwitchController\n",
    "\n",
    "import threading\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "gpu_available = tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zlaa_UTXvvnf"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'BipedalWalker-UTHAI'\n",
    "EPISODES = 500000\n",
    "TEST = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0yLopuYMvvng"
   },
   "outputs": [],
   "source": [
    "LAP = rospy.Publisher(\n",
    "        'uthai/l_ankle_pitch_position/command', Float64, queue_size=10)\n",
    "LAR = rospy.Publisher(\n",
    "    'uthai/l_ankle_roll_position/command', Float64, queue_size=10)\n",
    "LHP = rospy.Publisher(\n",
    "    'uthai/l_hip_pitch_position/command', Float64, queue_size=10)\n",
    "LHR = rospy.Publisher('uthai/l_hip_roll_position/command',\n",
    "                     Float64, queue_size=10)\n",
    "LHY = rospy.Publisher('uthai/l_hip_yaw_position/command',\n",
    "                      Float64, queue_size=10)\n",
    "LKP = rospy.Publisher(\n",
    "    'uthai/l_knee_pitch_position/command', Float64, queue_size=10)\n",
    "RAP = rospy.Publisher(\n",
    "    'uthai/r_ankle_pitch_position/command', Float64, queue_size=10)\n",
    "RAR = rospy.Publisher(\n",
    "    'uthai/r_ankle_roll_position/command', Float64, queue_size=10)\n",
    "RHP = rospy.Publisher(\n",
    "    'uthai/r_hip_pitch_position/command', Float64, queue_size=10)\n",
    "RHR = rospy.Publisher('uthai/r_hip_roll_position/command',\n",
    "                      Float64, queue_size=10)\n",
    "RHY = rospy.Publisher('uthai/r_hip_yaw_position/command',\n",
    "                      Float64, queue_size=10)\n",
    "RKP = rospy.Publisher(\n",
    "    'uthai/r_knee_pitch_position/command', Float64, queue_size=10)\n",
    "\n",
    "reset_simulation = rospy.ServiceProxy('/gazebo/reset_world', Empty)\n",
    "\n",
    "reset_joints = rospy.ServiceProxy('/gazebo/set_model_configuration', SetModelConfiguration)\n",
    "\n",
    "unpause = rospy.ServiceProxy('/gazebo/unpause_physics', Empty)\n",
    "\n",
    "pause = rospy.ServiceProxy('/gazebo/pause_physics', Empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "khFcTCjHvvng"
   },
   "outputs": [],
   "source": [
    "fall = 0\n",
    "rospy.init_node(\"q_set_control_node\")\n",
    "rate = rospy.Rate(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_H4lYv4zvvng"
   },
   "outputs": [],
   "source": [
    "class RobotState(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.outer_ring_inner_ring_theta = 0.0\n",
    "        \n",
    "        self.waist_z = 0.0\n",
    "\n",
    "        \n",
    "        self.LAP_theta = 0.0\n",
    "        self.LAP_theta_dot = 0.0\n",
    "        \n",
    "        self.LAR_theta = 0.0\n",
    "        self.LAR_theta_dot = 0.0\n",
    "        \n",
    "        self.LHP_theta = 0.0\n",
    "        self.LHP_theta_dot = 0.0\n",
    "        \n",
    "        self.LHR_theta = 0.0\n",
    "        self.LHR_theta_dot = 0.0\n",
    "        \n",
    "        self.LHY_theta = 0.0\n",
    "        self.LHY_theta_dot = 0.0\n",
    "        \n",
    "        self.LKP_theta = 0.0\n",
    "        self.LKP_theta_dot = 0.0\n",
    "        \n",
    "        self.RAP_theta = 0.0\n",
    "        self.RAP_theta_dot = 0.0\n",
    "        \n",
    "        self.RAR_theta = 0.0\n",
    "        self.RAR_theta_dot = 0.0\n",
    "        \n",
    "        self.RHP_theta = 0.0\n",
    "        self.RHP_theta_dot = 0.0\n",
    "        \n",
    "        self.RHR_theta = 0.0\n",
    "        self.RHR_theta_dot = 0.0\n",
    "        \n",
    "        self.RHY_theta = 0.0\n",
    "        self.RHY_theta_dot = 0.0\n",
    "        \n",
    "        self.RKP_theta = 0.0\n",
    "        self.RKP_theta_dot = 0.0\n",
    "        \n",
    " \n",
    "        #self.footr_contact = 0\n",
    "        #self.footl_contact = 0\n",
    "        \n",
    "        self.robot_state = [self.LAP_theta, self.LAP_theta_dot, self.LAR_theta, self.LAR_theta_dot, \\\n",
    "        self.LHP_theta, self.LHP_theta_dot, self.LHR_theta, self.LHR_theta_dot,self.LHY_theta,self.LHY_theta_dot,\\\n",
    "        self.LKP_theta,self.LKP_theta_dot,self.RAP_theta,self.RAP_theta_dot,\\\n",
    "        self.RAR_theta,self.RAR_theta_dot,self.RHP_theta,self.RHP_theta_dot,\\\n",
    "        self.RHR_theta,self.RHR_theta_dot,self.RHY_theta,self.RHY_theta_dot,self.RKP_theta,self.RKP_theta_dot]\n",
    "\n",
    "        self.latest_reward = 0.0\n",
    "        self.best_reward = -100000000000000.0\n",
    "        self.episode = 0\n",
    "        self.last_outer_ring_inner_ring_theta = 0.0\n",
    "        self.last_time = 0.0\n",
    "\n",
    "        self.fall = 0\n",
    "        self.done = False\n",
    "        self.count_of_1 = 0\n",
    "        self.avg_reward = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "d-FUA7ggvvnh"
   },
   "outputs": [],
   "source": [
    "class Publisher(threading.Thread):\n",
    "    def __init__(self,LAP,LAR,LHP,LHR,LHY,LKP,RAP,RAR,RHP,RHR,RHY,RKP, rate):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.counter = 0\n",
    "        self.LAP = LAP\n",
    "        self.LAR = LAR\n",
    "        self.LHP = LHP\n",
    "        self.LHR = LHR\n",
    "        self.LHY = LHY\n",
    "        self.LKP = LKP\n",
    "        self.RAP = RAP\n",
    "        self.RAR = RAR\n",
    "        self.RHP = RHP\n",
    "        self.RHR = RHR\n",
    "        self.RHY = RHY\n",
    "        self.RKP = RKP\n",
    "        \n",
    "        self.rate = rate\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        publisher(self.LAP,self.LAR,self.LHP,self.LHR,self.LHY,self.LKP,self.RAP,self.RAR,self.RHP,\\\n",
    "        self.RHR,self.RHY,self.RKP,self.rate, self.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3_LKr_xcvvnh"
   },
   "outputs": [],
   "source": [
    "robot_state = RobotState()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0chrd9zdvvni"
   },
   "outputs": [],
   "source": [
    "def set_robot_state():\n",
    "    robot_state.robot_state =  [robot_state.LAP_theta, robot_state.LAP_theta_dot, robot_state.LAR_theta, robot_state.LAR_theta_dot, \\\n",
    "        robot_state.LHP_theta, robot_state.LHP_theta_dot, robot_state.LHR_theta, robot_state.LHR_theta_dot,robot_state.LHY_theta,robot_state.LHY_theta_dot,\\\n",
    "        robot_state.LKP_theta,robot_state.LKP_theta_dot,robot_state.RAP_theta,robot_state.RAP_theta_dot,\\\n",
    "        robot_state.RAR_theta,robot_state.RAR_theta_dot,robot_state.RHP_theta,robot_state.RHP_theta_dot,\\\n",
    "        robot_state.RHR_theta,robot_state.RHR_theta_dot,robot_state.RHY_theta,robot_state.RHY_theta_dot,robot_state.RKP_theta,robot_state.RKP_theta_dot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "L9jpXkJRvvni"
   },
   "outputs": [],
   "source": [
    "def reset_joint_hassan():\n",
    "    LHY.publish(0)\n",
    "    RHY.publish(0)\n",
    "    LAR.publish(0)\n",
    "    LHR.publish(0)\n",
    "    RAR.publish(0)\n",
    "    RHR.publish(0)\n",
    "\n",
    "    LHP.publish(0)\n",
    "    LKP.publish(0)\n",
    "    LAP.publish(0)\n",
    "    RHP.publish(0)\n",
    "    RKP.publish(0)\n",
    "    RAP.publish(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8hxeLGlCvvni"
   },
   "outputs": [],
   "source": [
    "def Reset() :\n",
    "     for _ in range(2):\n",
    "            reset()\n",
    "            \n",
    "     try:\n",
    "        pause()\n",
    "     except (rospy.ServiceException) as e:\n",
    "        print (\"rospause failed!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yavlZhCKvvni"
   },
   "outputs": [],
   "source": [
    "def reset():\n",
    "    # ['waist_thighR', 'waist_thighL', 'thighR_shankR', 'thighL_shankL', 'outer_ring_inner_ring', 'inner_ring_boom', 'boom_waist']\n",
    "\n",
    "    rospy.wait_for_service('gazebo/set_model_configuration')\n",
    "    \n",
    "    try:\n",
    "        reset_joint_hassan()\n",
    "        #delay_error()\n",
    "        robot_state.last_outer_ring_inner_ring_theta = 0.0\n",
    "        \n",
    "        \n",
    "    except (rospy.ServiceException) as e:\n",
    "        print (\"reset_joints failed!\")\n",
    "    \n",
    "    rospy.wait_for_service('/gazebo/pause_physics')\n",
    "\n",
    "    \n",
    "    rospy.wait_for_service('gazebo/reset_world')\n",
    "    try:\n",
    "        reset_simulation()\n",
    "        \n",
    "    except(rospy.ServiceException) as e :\n",
    "        print (\"reset_world failed!\")\n",
    "        \n",
    "    #time.sleep(1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pause()\n",
    "        print(\"-------------paused_simulation-----------\")\n",
    "    except (rospy.ServiceException) as e:\n",
    "        print (\"rospause failed!'\")\n",
    "    \"\"\"\n",
    "    set_robot_state()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jbt73G9cvvnj"
   },
   "outputs": [],
   "source": [
    "def best_reset():        \n",
    "        rospy.wait_for_service('/gazebo/delete_model')\n",
    "        try:\n",
    "                DeleteModel()\n",
    "\n",
    "        except (rospy.ServiceException) as e:\n",
    "                print (\"delete model  failed!\")\n",
    "        rospy.wait_for_service('/gazebo/spawn_urdf_model')\n",
    "        try:\n",
    "                SpawnModel()\n",
    "\n",
    "        except (rospy.ServiceException) as e:\n",
    "\n",
    "               print (\"spawn_urdf_model failed!\")\n",
    "        try:\n",
    "           pause()\n",
    "        except (rospy.ServiceException) as e:\n",
    "           print (\"pause failed!'\")\n",
    "        rospy.wait_for_service('gazebo/set_model_configuration')\n",
    "\n",
    "        try:\n",
    "                reset_joint_hassan()\n",
    "                robot_state.last_outer_ring_inner_ring_theta = 0.0\n",
    "\n",
    "        except (rospy.ServiceException) as e:\n",
    "                print (\"reset_joints failed!\")\n",
    "        \n",
    "        \n",
    "        try:\n",
    "           unpause()\n",
    "        except (rospy.ServiceException) as e:\n",
    "           print (\"unpause failed!'\")\n",
    "        rospy.wait_for_service(\"/uthai/controller_manager/load_controller\")\n",
    "        \n",
    "        error_compensator()\n",
    "\n",
    "        try:\n",
    "           LoadController()\n",
    "        except (rospy.ServiceException) as e:\n",
    "           print (\"LoadController failed!'\")\n",
    "        rospy.wait_for_service(\"/uthai/controller_manager/switch_controller\")\n",
    "        try:\n",
    "           SwitchController()\n",
    "        except (rospy.ServiceException) as e:\n",
    "           print (\"SwitchController failed!\")\n",
    "        rospy.wait_for_service('gazebo/reset_world')\n",
    "        try:\n",
    "            reset_simulation()\n",
    "        \n",
    "        except(rospy.ServiceException) as e :\n",
    "            print (\"reset_world failed!\")\n",
    "        reset_joint_hassan()\n",
    "        time.sleep(1)\n",
    "        set_robot_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "l62X6hmlvvnp"
   },
   "outputs": [],
   "source": [
    "def error_compensator() :\n",
    "    \n",
    "    st= time.time()\n",
    "    global break_loop\n",
    "    while True : \n",
    "         a = tf.constant([robot_state.LAP_theta ,robot_state.LAR_theta ,robot_state.LHP_theta ,robot_state.LHR_theta ,\n",
    "robot_state.LHY_theta ,robot_state.LKP_theta, robot_state.RAP_theta, robot_state.RAR_theta ,\n",
    "robot_state.RHP_theta ,robot_state.RHR_theta, robot_state.RHY_theta ,robot_state.RKP_theta ])\n",
    "         error_norm = tf.norm(a,ord=2)#norm1\n",
    "         \n",
    "         if error_norm < 0.03 or abs(robot_state.outer_ring_inner_ring_theta)>9:\n",
    "                break\n",
    "         if abs(st-time.time()) > 300 :\n",
    "                break_loop = True\n",
    "                print(\"-----------tool_keshid_oomadam_biroon--------\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "D9aH7y3zvvnj"
   },
   "outputs": [],
   "source": [
    "def take_action(action):\n",
    "    rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "\n",
    "    try:\n",
    "        unpause()\n",
    "    except (rospy.ServiceException) as e:\n",
    "        print (\"/gazebo/pause_physics service call failed\")\n",
    "    #print(\"ok i am in before scler\")\n",
    "    \n",
    "    action = map_scaler(action)    \n",
    "    #print(\"ok iam in after scaler\")\n",
    "    LAP.publish(action[0])\n",
    "    #LAR.publish(0)\n",
    "    LHP.publish(action[2])\n",
    "    #LHR.publish(0)\n",
    "    LHY.publish(action[4])\n",
    "    LKP.publish(action[5])\n",
    "    RAP.publish(action[6])\n",
    "    #RAR.publish(0)\n",
    "    RHP.publish(action[8])\n",
    "    #RHR.publish(0)\n",
    "    RHY.publish(action[10])\n",
    "    RKP.publish(action[11])\n",
    "\n",
    "\n",
    "    reward = -0.1  # when it used to run, used to be -0.1\n",
    "    current_time = time.time()\n",
    "    \n",
    "    #print(robot_state.waist_z)\n",
    "    if robot_state.waist_z > 0.40 and robot_state.waist_z < 0.85 :#0.36\n",
    "        #print(\"ekhtelaf:\",robot_state.outer_ring_inner_ring_theta - robot_state.last_outer_ring_inner_ring_theta)\n",
    "        #if  (robot_state.outer_ring_inner_ring_theta - robot_state.last_outer_ring_inner_ring_theta) >= 0.09: #-0.001forward motion\n",
    "\n",
    "            delta_time = current_time - robot_state.last_time\n",
    "\n",
    "            reward += ((robot_state.outer_ring_inner_ring_theta - robot_state.last_outer_ring_inner_ring_theta))*100\n",
    "    else :\n",
    "        reward += -100\n",
    "        #print(\"i am in if 1\")\n",
    "        robot_state.done = True\n",
    "        robot_state.fall = 1\n",
    "        \n",
    "    if robot_state.outer_ring_inner_ring_theta > 9.0:\n",
    "        #reward += 100\n",
    "        #print('i am in if 2')\n",
    "        robot_state.done = True\n",
    "        robot_state.fall = 1\n",
    "        break_loop = True\n",
    "        print(\"-----------tool_keshid_oomadam_biroon--------\")\n",
    "        print (\"REACHED TO THE END!\")\n",
    "\n",
    "    robot_state.last_time = current_time\n",
    "    robot_state.last_outer_ring_inner_ring_theta = robot_state.outer_ring_inner_ring_theta\n",
    "    \n",
    "    #\"outer_ring_inner_ring_theta :\",robot_state.outer_ring_inner_ring_theta,\n",
    "    #      \"last_outer_ring_inner_ring_theta:\",robot_state.last_outer_ring_inner_ring_theta,\n",
    "    #     \"ekhtelaf :\",robot_state.outer_ring_inner_ring_theta - robot_state.last_outer_ring_inner_ring_theta)\n",
    "    rate.sleep()\n",
    "    return reward, robot_state.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fYh50AQzvvnj"
   },
   "outputs": [],
   "source": [
    "def callbackJointStates(data):\n",
    "\n",
    "    robot_state.data = data\n",
    "    \n",
    "\n",
    "    if len(data.velocity)!=0:\n",
    "        \n",
    "        robot_state.LAP_theta_dot = data.velocity[0]\n",
    "        \n",
    "        robot_state.LAR_theta_dot = data.velocity[1]\n",
    "        \n",
    "        robot_state.LHP_theta_dot = data.velocity[2]\n",
    "        \n",
    "        robot_state.LHR_theta_dot = data.velocity[3]\n",
    "        \n",
    "        robot_state.LHY_theta_dot = data.velocity[4]\n",
    "        \n",
    "        robot_state.LKP_theta_dot = data.velocity[5]\n",
    "        \n",
    "        robot_state.RAP_theta_dot = data.velocity[6]\n",
    "        \n",
    "        robot_state.RAR_theta_dot = data.velocity[7]\n",
    "        \n",
    "        robot_state.RHP_theta_dot = data.velocity[8]\n",
    "        \n",
    "        robot_state.RHR_theta_dot = data.velocity[9]\n",
    "        \n",
    "        robot_state.RHY_theta_dot = data.velocity[10]\n",
    "        \n",
    "        robot_state.RKP_theta_dot = data.velocity[11]\n",
    "        \n",
    "\n",
    "\n",
    "        robot_state.LAP_theta = data.position[0]\n",
    "        robot_state.LAR_theta = data.position[1]\n",
    "        robot_state.LHP_theta = data.position[2]\n",
    "        robot_state.LHR_theta = data.position[3]\n",
    "        robot_state.LHY_theta = data.position[4]\n",
    "        robot_state.LKP_theta = data.position[5]\n",
    "        robot_state.RAP_theta = data.position[6]\n",
    "        robot_state.RAR_theta = data.position[7]\n",
    "        robot_state.RHP_theta = data.position[8]\n",
    "        robot_state.RHR_theta = data.position[9]\n",
    "        robot_state.RHY_theta = data.position[10]\n",
    "        robot_state.RKP_theta = data.position[11]\n",
    "\n",
    "        \n",
    "\n",
    "    else:\n",
    "        robot_state.LAP_theta_dot = 0\n",
    "        \n",
    "        robot_state.LAR_theta_dot = 0\n",
    "        \n",
    "        robot_state.LHP_theta_dot = 0\n",
    "        \n",
    "        robot_state.LHR_theta_dot = 0\n",
    "        \n",
    "        robot_state.LHY_theta_dot = 0\n",
    "        \n",
    "        robot_state.LKP_theta_dot = 0\n",
    "        \n",
    "        robot_state.RAP_theta_dot = 0\n",
    "        \n",
    "        robot_state.RAR_theta_dot = 0\n",
    "        \n",
    "        robot_state.RHP_theta_dot = 0\n",
    "        \n",
    "        robot_state.RHR_theta_dot = 0\n",
    "        \n",
    "        robot_state.RHY_theta_dot = 0\n",
    "        \n",
    "        robot_state.RKP_theta_dot = 0\n",
    "\n",
    "        robot_state.LAP_theta = 0\n",
    "        robot_state.LAR_theta = 0\n",
    "        robot_state.LHP_theta = 0\n",
    "        robot_state.LHR_theta = 0\n",
    "        robot_state.LHY_theta = 0\n",
    "        robot_state.LKP_theta = 0\n",
    "        robot_state.RAP_theta = 0\n",
    "        robot_state.RAR_theta = 0\n",
    "        robot_state.RHP_theta = 0\n",
    "        robot_state.RHR_theta = 0\n",
    "        robot_state.RHY_theta = 0\n",
    "        robot_state.RKP_theta = 0\n",
    "\n",
    "    set_robot_state()\n",
    "    #rate.sleep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "CAAcVkUsvvnj"
   },
   "outputs": [],
   "source": [
    "def callbackSub(data):\n",
    "    set_robot_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BC0u_m_wvvnk"
   },
   "outputs": [],
   "source": [
    "def callbackContactShankR(data):\n",
    "    if not data.states:\n",
    "        robot_state.footr_contact = 0\n",
    "    else:\n",
    "        robot_state.footr_contact = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "U63W9grrvvnk"
   },
   "outputs": [],
   "source": [
    "def callbackContactShankL(data):\n",
    "    if not data.states:\n",
    "        robot_state.footl_contact = 0\n",
    "    else:\n",
    "        robot_state.footl_contact = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "jrMEzNYivvnk"
   },
   "outputs": [],
   "source": [
    "def Posecallback(data):\n",
    "    try:\n",
    "      ind = data.name.index(\"uthai::base_link\")\n",
    "      link_pose = data.pose[ind].position\n",
    "\n",
    "      robot_state.outer_ring_inner_ring_theta = link_pose.x\n",
    "      robot_state.waist_z = link_pose.z\n",
    "    except ValueError:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Pn1qR28xvvnk"
   },
   "outputs": [],
   "source": [
    "def listener():\n",
    "    print (\"listener\")\n",
    "    #LAR.publish(0)\n",
    "    #LHR.publish(0)\n",
    "    #RAR.publish(0)\n",
    "    #RHR.publish(0)\n",
    "\n",
    "    rospy.Subscriber(\"/uthai/joint_states\", JointState, callbackJointStates)\n",
    "    \n",
    "    rospy.Subscriber(\"/gazebo/link_states\", LinkStates, Posecallback)\n",
    "    \n",
    "    \n",
    "    #rospy.Subscriber(\"/l_bumper_topic\",ContactsState,callback_contact_l)\n",
    "    #rospy.Subscriber(\"/r_bumper_topic\" ,ContactsState,callback_contact_r)\n",
    "    #rospy.Subscriber(\"/footR_contact_sensor_state\", ContactsState, callbackContactShankR)\n",
    "    #rospy.Subscriber(\"/footL_contact_sensor_state\", ContactsState, callbackContactShankL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "791Sximhvvnk"
   },
   "outputs": [],
   "source": [
    "#def callback_contact_l(data) :\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "R2-w4y-g0LiV"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5sW0IEPJ0a6U"
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "b4TvnA6i2mxH"
   },
   "outputs": [],
   "source": [
    "class Actor(Model):\n",
    "\n",
    "    def __init__(self, action_dim):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.dense1_layer = layers.Dense(400)\n",
    "        self.dense2_layer = layers.Dense(300)\n",
    "        self.mean_layer = layers.Dense(self.action_dim)\n",
    "        self.stdev_layer = layers.Dense(self.action_dim)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.act1=layers.Activation(\"relu\")\n",
    "        self.act2=layers.Activation(\"relu\")\n",
    "        \n",
    "    def call(self, state):\n",
    "        # Get mean and standard deviation from the policy network\n",
    "        \n",
    "        #print(\"state\",state)\n",
    "        state= self.dense1_layer(state)\n",
    "        state= self.bn1(state)\n",
    "        a1= self.act1(state)\n",
    "        #print(\"a1:\",a1)\n",
    "        #print()\n",
    "        a1 = self.dense2_layer(a1)\n",
    "        a1= self.bn2(a1)\n",
    "        a2= self.act2(a1)\n",
    "\n",
    "        #print(\"a2:\",a2)\n",
    "        mu = self.mean_layer(a2)\n",
    "        #print(\"mu\",mu)\n",
    "        # Standard deviation is bounded by a constraint of being non-negative\n",
    "        # therefore we produce log stdev as output which can be [-inf, inf]\n",
    "        log_sigma = self.stdev_layer(a2)\n",
    "        #print(\"log_sigma\",log_sigma)\n",
    "        sigma = tf.exp(log_sigma)\n",
    "        #print(\"sigma\",sigma)\n",
    "        # Use re-parameterization trick to deterministically sample action from\n",
    "        # the policy network. First, sample from a Normal distribution of\n",
    "        # sample size as the action and multiply it with stdev\n",
    "        dist = tfp.distributions.Normal(mu, sigma)\n",
    "        action_ = dist.sample()\n",
    "\n",
    "        # Apply the tanh squashing to keep the gaussian bounded in (-1,1)\n",
    "        action = tf.tanh(action_)\n",
    "\n",
    "        # Calculate the log probability\n",
    "        log_pi_ = dist.log_prob(action_)\n",
    "        # Change log probability to account for tanh squashing as mentioned in\n",
    "        # Appendix C of the paper\n",
    "        log_pi = log_pi_ - tf.reduce_sum(tf.math.log(1 - action**2 + EPSILON), axis=1,\n",
    "                                         keepdims=True)\n",
    "\n",
    "        return action, log_pi\n",
    "\n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return self.dense1_layer.trainable_variables + \\\n",
    "                self.dense1_layer.trainable_variables + \\\n",
    "                self.mean_layer.trainable_variables + \\\n",
    "                self.stdev_layer.trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "29w8Bu4-HeZc"
   },
   "outputs": [],
   "source": [
    "class Critic(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1_layer = layers.Dense(400, activation=tf.nn.relu)\n",
    "        self.dense2_layer = layers.Dense(300, activation=tf.nn.relu)\n",
    "        self.output_layer = layers.Dense(1)\n",
    "\n",
    "    def call(self, state, action):\n",
    "        state_action = tf.concat([state, action], axis=1)\n",
    "        a1 = self.dense1_layer(state_action)\n",
    "        a2 = self.dense2_layer(a1)\n",
    "        q = self.output_layer(a2)\n",
    "        return q\n",
    "\n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return self.dense1_layer.trainable_variables + \\\n",
    "                self.output_layer.trainable_variables + \\\n",
    "                self.dense2_layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "7wSxi_WSIeyU"
   },
   "outputs": [],
   "source": [
    "class SoftActorCritic:\n",
    "\n",
    "    def __init__(self, action_dim, writer, epoch_step=1, learning_rate=1e-3,\n",
    "                 alpha=0.2, gamma=0.99,\n",
    "                polyak=0.995):\n",
    "        self.policy = Actor(action_dim)\n",
    "        self.q1 = Critic()\n",
    "        self.q2 = Critic()\n",
    "        self.target_q1 = Critic()\n",
    "        self.target_q2 = Critic()\n",
    "\n",
    "        self.writer = writer\n",
    "        self.epoch_step = epoch_step\n",
    "\n",
    "        self.alpha = tf.Variable(0.0, dtype=tf.float64)\n",
    "        self.target_entropy = -tf.constant(action_dim, dtype=tf.float64)\n",
    "        self.gamma = gamma\n",
    "        self.polyak = polyak\n",
    "\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        self.critic1_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        self.critic2_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        self.alpha_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "    def sample_action(self, current_state):\n",
    "        current_state_ = np.array(current_state, ndmin=2)\n",
    "        action, _ = self.policy(current_state_)\n",
    "        return action[0]\n",
    "\n",
    "\n",
    "    def update_q_network(self, current_states, actions, rewards, next_states, ends):\n",
    "\n",
    "        with tf.GradientTape() as tape1:\n",
    "            # Get Q value estimates, action used here is from the replay buffer\n",
    "            q1 = self.q1(current_states, actions)\n",
    "\n",
    "            # Sample actions from the policy for next states\n",
    "            pi_a, log_pi_a = self.policy(next_states)\n",
    "\n",
    "            # Get Q value estimates from target Q network\n",
    "            q1_target = self.target_q1(next_states, pi_a)\n",
    "            q2_target = self.target_q2(next_states, pi_a)\n",
    "\n",
    "            # Apply the clipped double Q trick\n",
    "            # Get the minimum Q value of the 2 target networks\n",
    "            min_q_target = tf.minimum(q1_target, q2_target)\n",
    "\n",
    "            # Add the entropy term to get soft Q target\n",
    "            soft_q_target = min_q_target - self.alpha * log_pi_a\n",
    "            y = tf.stop_gradient(rewards + self.gamma * ends * soft_q_target)\n",
    "\n",
    "            critic1_loss = tf.reduce_mean((q1 - y)**2)\n",
    "\n",
    "        with tf.GradientTape() as tape2:\n",
    "            # Get Q value estimates, action used here is from the replay buffer\n",
    "            q2 = self.q2(current_states, actions)\n",
    "\n",
    "            # Sample actions from the policy for next states\n",
    "            pi_a, log_pi_a = self.policy(next_states)\n",
    "\n",
    "            # Get Q value estimates from target Q network\n",
    "            q1_target = self.target_q1(next_states, pi_a)\n",
    "            q2_target = self.target_q2(next_states, pi_a)\n",
    "\n",
    "            # Apply the clipped double Q trick\n",
    "            # Get the minimum Q value of the 2 target networks\n",
    "            min_q_target = tf.minimum(q1_target, q2_target)\n",
    "\n",
    "            # Add the entropy term to get soft Q target\n",
    "            soft_q_target = min_q_target - self.alpha * log_pi_a\n",
    "            y = tf.stop_gradient(rewards + self.gamma * ends * soft_q_target)\n",
    "\n",
    "            critic2_loss = tf.reduce_mean((q2 - y)**2)\n",
    "\n",
    "        grads1 = tape1.gradient(critic1_loss, self.q1.trainable_variables)\n",
    "        self.critic1_optimizer.apply_gradients(zip(grads1,\n",
    "                                                   self.q1.trainable_variables))\n",
    "\n",
    "        grads2 = tape2.gradient(critic2_loss, self.q2.trainable_variables)\n",
    "        self.critic2_optimizer.apply_gradients(zip(grads2,\n",
    "                                                   self.q2.trainable_variables))\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            for grad, var in zip(grads1, self.q1.trainable_variables):\n",
    "                tf.summary.histogram(f\"grad-{var.name}\", grad, self.epoch_step)\n",
    "                tf.summary.histogram(f\"var-{var.name}\", var, self.epoch_step)\n",
    "            for grad, var in zip(grads2, self.q2.trainable_variables):\n",
    "                tf.summary.histogram(f\"grad-{var.name}\", grad, self.epoch_step)\n",
    "                tf.summary.histogram(f\"var-{var.name}\", var, self.epoch_step)\n",
    "\n",
    "        return critic1_loss, critic2_loss\n",
    "\n",
    "    def update_policy_network(self, current_states):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Sample actions from the policy for current states\n",
    "            pi_a, log_pi_a = self.policy(current_states)\n",
    "\n",
    "            # Get Q value estimates from target Q network\n",
    "            q1 = self.q1(current_states, pi_a)\n",
    "            q2 = self.q2(current_states, pi_a)\n",
    "\n",
    "            # Apply the clipped double Q trick\n",
    "            # Get the minimum Q value of the 2 target networks\n",
    "            min_q = tf.minimum(q1, q2)\n",
    "\n",
    "            soft_q = min_q - self.alpha * log_pi_a\n",
    "\n",
    "            actor_loss = -tf.reduce_mean(soft_q)\n",
    "\n",
    "        variables = self.policy.trainable_variables\n",
    "        grads = tape.gradient(actor_loss, variables)\n",
    "        self.actor_optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            for grad, var in zip(grads, variables):\n",
    "                tf.summary.histogram(f\"grad-{var.name}\", grad, self.epoch_step)\n",
    "                tf.summary.histogram(f\"var-{var.name}\", var, self.epoch_step)\n",
    "\n",
    "        return actor_loss\n",
    "\n",
    "\n",
    "    def update_alpha(self, current_states):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Sample actions from the policy for current states\n",
    "            pi_a, log_pi_a = self.policy(current_states)\n",
    "\n",
    "            alpha_loss = tf.reduce_mean( - self.alpha*(log_pi_a +\n",
    "                                                       self.target_entropy))\n",
    "\n",
    "        variables = [self.alpha]\n",
    "        grads = tape.gradient(alpha_loss, variables)\n",
    "        self.alpha_optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            for grad, var in zip(grads, variables):\n",
    "                tf.summary.histogram(f\"grad-{var.name}\", grad, self.epoch_step)\n",
    "                tf.summary.histogram(f\"var-{var.name}\", var, self.epoch_step)\n",
    "\n",
    "        return alpha_loss\n",
    "\n",
    "\n",
    "    def train(self, current_states, actions, rewards, next_states, ends):\n",
    "\n",
    "        # Update Q network weights\n",
    "        critic1_loss, critic2_loss = self.update_q_network(current_states, actions, rewards, next_states, ends)\n",
    "\n",
    "        # Update policy network weights\n",
    "        actor_loss = self.update_policy_network(current_states)\n",
    "\n",
    "        alpha_loss = self.update_alpha(current_states)\n",
    "\n",
    "        # Update target Q network weights\n",
    "        #self.update_weights()\n",
    "\n",
    "        #if self.epoch_step % 10 == 0:\n",
    "        #    self.alpha = max(0.1, 0.9**(1+self.epoch_step/10000))\n",
    "        #    print(\"alpha: \", self.alpha, 1+self.epoch_step/10000)\n",
    "\n",
    "        return critic1_loss, critic2_loss, actor_loss, alpha_loss\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        for theta_target, theta in zip(self.target_q1.trainable_variables,\n",
    "                                       self.q1.trainable_variables):\n",
    "            theta_target = self.polyak * theta_target + (1 - self.polyak) * theta\n",
    "\n",
    "        for theta_target, theta in zip(self.target_q2.trainable_variables,\n",
    "                                       self.q2.trainable_variables):\n",
    "            theta_target = self.polyak * theta_target + (1 - self.polyak) * theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "DrzwpHBEDsVs"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, state_space, action_space, max_size=300000):\n",
    "        self.current_states = np.empty((0, state_space), dtype=np.float64)\n",
    "        self.actions = np.empty((0, action_space), dtype=np.float64)\n",
    "        self.rewards = np.empty((0, 1), dtype=np.float64)\n",
    "        self.next_states = np.empty((0, state_space), dtype=np.float64)\n",
    "        self.ends = np.empty((0, 1), dtype=np.float64)\n",
    "        self.total_size = 0\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def store(self, current_state, action, reward, next_state, end):\n",
    "        self.current_states = np.append(self.current_states[-self.max_size:],\n",
    "                                        np.array(current_state, ndmin=2), axis=0)\n",
    "        \n",
    "        self.actions = np.append(self.actions[-self.max_size:],\n",
    "                                 np.array(action, ndmin=2), axis=0)\n",
    "\n",
    "        self.rewards = np.append(self.rewards[-self.max_size:],\n",
    "                                 np.array(reward, ndmin=2), axis=0)\n",
    "        self.next_states = np.append(self.next_states[-self.max_size:],\n",
    "                                     np.array(next_state, ndmin=2), axis=0)\n",
    "        self.ends = np.append(self.ends[-self.max_size:],\n",
    "                              np.array(end, ndmin=2), axis=0)\n",
    "        self.total_size += 1\n",
    "\n",
    "    def fetch_sample(self, num_samples):\n",
    "   \n",
    "        if num_samples > self.total_size:\n",
    "            num_samples = self.total_size\n",
    "       \n",
    "        idx = np.random.choice(range(min(self.total_size, self.max_size)),\n",
    "                               size=num_samples,\n",
    "                               replace=False)\n",
    "        current_states_ = self.current_states[idx]\n",
    "        actions_ = self.actions[idx]\n",
    "        rewards_ = self.rewards[idx]\n",
    "        next_states_ = self.next_states[idx]\n",
    "        ends_ = self.ends[idx]\n",
    "\n",
    "        return current_states_, actions_, rewards_, next_states_, ends_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "In5g8E0cJpmI",
    "outputId": "b0577681-dbc7-4b8f-968f-8aacafdc3e2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--learning_rate'], dest='learning_rate', nargs=None, const=None, default=0.001, type=<class 'float'>, choices=None, help='learning rate', metavar=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(level='INFO')\n",
    "\n",
    "parser = argparse.ArgumentParser(description='SAC')\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--env_name', type=str, default='MountainCarContinuous-v0',\n",
    "                    help='name of the gym environment with version')\n",
    "parser.add_argument('--render', type=bool, default=False,\n",
    "                    help='set gym environment to render display')\n",
    "parser.add_argument('--verbose', type=bool, default=False,\n",
    "                    help='log execution details')\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='minibatch sample size for training')\n",
    "parser.add_argument('--epochs', type=int, default=50,\n",
    "                    help='number of epochs to run backprop in an episode')\n",
    "parser.add_argument('--start_steps', type=int, default=0,\n",
    "                    help='number of global steps before random exploration ends')\n",
    "parser.add_argument('--model_path', type=str, default='../data/models/',\n",
    "                    help='path to save model')\n",
    "parser.add_argument('--model_name', type=str,\n",
    "                    default=f'{str(datetime.utcnow().date())}-{str(datetime.utcnow().time())}',\n",
    "                    help='name of the saved model')\n",
    "parser.add_argument('--gamma', type=float, default=0.99,\n",
    "                    help='discount factor for future rewards')\n",
    "parser.add_argument('--polyak', type=float, default=0.995,\n",
    "                    help='coefficient for polyak averaging of Q network weights')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                    help='learning rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDW_rx-xQP2h",
    "outputId": "d8a7f0dd-88f5-4a89-c9f2-7d5d3ebd3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space : 24   action_space : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 04:36:34.516555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.516970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.517245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.517743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.518123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.518436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.518794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.519103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 04:36:34.519400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2126 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(args.seed)\n",
    "writer = tf.summary.create_file_writer('../data/models/' + f'{str(datetime.utcnow().date())}-{str(datetime.utcnow().time())}' + '/summary')\n",
    "state_space = 24 #state_space\n",
    "action_space = 12 #action space\n",
    "\n",
    "print(\"state space :\" , state_space , \"  action_space :\" ,  action_space)\n",
    "\n",
    "replay = ReplayBuffer(state_space, action_space)\n",
    "\n",
    "sac = SoftActorCritic(action_space, writer,\n",
    "                      learning_rate=0.001,\n",
    "                      gamma=0.99, polyak=0.995)\n",
    "#sac.policy.load_weights('../data/models' + '/2021-09-25-10:24:27.970811/model')\n",
    "#sac.policy.load_weights(\"model\")\n",
    "old_action_min = -1\n",
    "old_action_max = +1\n",
    "#                             LAP,      LAR   ,LHP,  LHR,  LHY,LKP,  RAP,  RAR,  RHP,   RHR,  RHY,RKP\n",
    "new_action_min = tf.constant([ -0.349, 0.0, -1.396 , 0.0,-0.8, 0.0,-0.349, 0.0,-1.396,  0.0, -0.8, 0],dtype =tf.float64)\n",
    "new_action_max = tf.constant([1.047  , 0.0,  1.396 , 0.0, 0.8, 1.4, 1.047, 0.0, 1.396,  0.0 , 0.8,1.4],dtype =tf.float64)\n",
    "\n",
    "uniform_sampling= tfp.distributions.Uniform(\n",
    "    low=new_action_min, \n",
    "    high=new_action_max, validate_args=False, allow_nan_stats=True,\n",
    "    name='Uniform'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "xVMefObzvvnn"
   },
   "outputs": [],
   "source": [
    "def map_scaler(action) :\n",
    "   \n",
    "   new_action = tf.math.multiply((action - old_action_min)/(old_action_max-old_action_min),new_action_max-new_action_min) + new_action_min\n",
    "   return new_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hassan/catkin_ws/src/UTHAI-Common/uthai_gazebo/scripts/SAC\n"
     ]
    }
   ],
   "source": [
    "cd ~/catkin_ws/src/UTHAI-Common/uthai_gazebo/scripts/SAC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "replay.actions = np.load('actions.npy')    # .npy extension is added if not given\n",
    "replay.current_states = np.load('current_states.npy')    # .npy extension is added if not given\n",
    "replay.next_states = np.load('next_states.npy')    # .npy extension is added if not given\n",
    "replay.ends = np.load('ends.npy')    # .npy extension is added if not given\n",
    "replay.rewards = np.load('rewards.npy')    # .npy extension is added if not given\n",
    "replay.total_size= len(replay.actions)\n",
    "break_loop=False\n",
    "episode_rewards=list(np.load('episode_rewards.npy'))\n",
    "episode=replay.total_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hassan/catkin_ws/src/UTHAI-Common/uthai_gazebo/scripts/data/models/2021-10-31-08:31:28.564283\n"
     ]
    }
   ],
   "source": [
    "cd ~/catkin_ws/src/UTHAI-Common/uthai_gazebo/scripts/data/models/2021-10-31-08:31:28.564283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f849682d760>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac.policy.load_weights(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac.policy.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_loop=False\n",
    "episode=1\n",
    "episode_rewards=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_loop=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "djgHNP9yKSUH"
   },
   "outputs": [],
   "source": [
    "# Repeat until convergence\n",
    "\n",
    "def publisher(LAP,LAR,LHP,LHR,LHY,LKP,RAP,RAR,RHP,RHR,RHY,RKP,rate,counter):\n",
    "\n",
    "            count = 0\n",
    "        \n",
    "            render = False\n",
    "            start_steps=0 \n",
    "            verbose=False\n",
    "            epochs=50\n",
    "            batch_size=256\n",
    "\n",
    "            global_step = 1\n",
    "            global episode\n",
    "            global episode_rewards\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            while not rospy.is_shutdown() :\n",
    "               \n",
    "                #if count == 1:\n",
    "                #    break\n",
    "\n",
    "                # Observe state\n",
    "                if break_loop == True:\n",
    "                    print(episode_rewards)\n",
    "                    break\n",
    "                best_reset()\n",
    "\n",
    "                current_state =np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],dtype=\"float32\")#shape = (24,)\n",
    "\n",
    "                step = 1\n",
    "                episode_reward = 0\n",
    "                done = False\n",
    "                robot_state.done=False\n",
    "                while not done:\n",
    "\n",
    "\n",
    "                    if global_step < start_steps:\n",
    "\n",
    "                        if np.random.uniform() > 0.8:\n",
    "                            action = uniform_sampling.sample()\n",
    "                        else:\n",
    "                            action = sac.sample_action(current_state)\n",
    "                    else:\n",
    "                        action = sac.sample_action(current_state)\n",
    "\n",
    "                    # Execute action, observe next state and reward\n",
    "                    #print(\"action: \",action,\"****\",robot_state.robot_state)\n",
    "                    #count = count  + 1 \n",
    "                    #print(\"action : \" , action)\n",
    "                    #print(\"***************\")\n",
    "                    reward,done = take_action(action)#ros\n",
    "                    #print(reward,done)\n",
    "                    #print(\"****************************************\")\n",
    "                    next_state = robot_state.robot_state\n",
    "\n",
    "                    episode_reward +=  reward\n",
    "\n",
    "                    # Set end to 0 if the episode ends otherwise make it 1\n",
    "                    # although the meaning is opposite but it is just easier to mutiply\n",
    "                    # with reward for the last step.\n",
    "                    if done:\n",
    "                        end = 0\n",
    "                    else:\n",
    "                        end = 1\n",
    "\n",
    "                    if verbose:\n",
    "                        logging.info(f'Global step: {global_step}')\n",
    "                        logging.info(f'current_state: {current_state}')\n",
    "                        logging.info(f'action: {action}')\n",
    "                        logging.info(f'reward: {reward}')\n",
    "                        logging.info(f'next_state: {next_state}')\n",
    "                        logging.info(f'end: {end}')\n",
    "\n",
    "                    # Store transition in replay buffer\n",
    "                    \n",
    "                    replay.store(current_state, action, reward, next_state, end)\n",
    "                    # Update current state\n",
    "                    current_state = next_state\n",
    "\n",
    "                    step += 1\n",
    "                    global_step += 1\n",
    "\n",
    "\n",
    "                \n",
    "                if (step % 1 == 0) and (global_step > start_steps):\n",
    "                    for epoch in range(epochs):\n",
    "\n",
    "                        # Randomly sample minibatch of transitions from replay buffer\n",
    "                        #print(\"in fetch smaple  ............\")\n",
    "                        current_states, actions, rewards, next_states, ends = replay.fetch_sample(num_samples=batch_size)\n",
    "\n",
    "                        # Perform single step of gradient descent on Q and policy\n",
    "                        # network\n",
    "                        #print(\"in training ...............\")\n",
    "                        critic1_loss, critic2_loss, actor_loss, alpha_loss = sac.train(current_states, actions, rewards, next_states, ends)\n",
    "                        #print(\"exit.....\")\n",
    "                        if verbose:\n",
    "                            print(episode, global_step, epoch, critic1_loss.numpy(),\n",
    "                                  critic2_loss.numpy(), actor_loss.numpy(), episode_reward)\n",
    "\n",
    "\n",
    "                        with writer.as_default():\n",
    "                            tf.summary.scalar(\"actor_loss\", actor_loss, sac.epoch_step)\n",
    "                            tf.summary.scalar(\"critic1_loss\", critic1_loss, sac.epoch_step)\n",
    "                            tf.summary.scalar(\"critic2_loss\", critic2_loss, sac.epoch_step)\n",
    "                            tf.summary.scalar(\"alpha_loss\", alpha_loss, sac.epoch_step)\n",
    "\n",
    "                        sac.epoch_step += 1\n",
    "\n",
    "                        if sac.epoch_step % 1 == 0:\n",
    "                            sac.update_weights()\n",
    "\n",
    "\n",
    "                if episode % 1 == 0:\n",
    "                    sac.policy.save_weights('../data/models/' + f'{str(datetime.utcnow().date())}-{str(datetime.utcnow().time())}' + '/model')\n",
    "\n",
    "                episode_rewards.append(episode_reward)\n",
    "                episode += 1\n",
    "\n",
    "                avg_episode_reward = sum(episode_rewards[-100:])/len(episode_rewards[-100:])\n",
    "\n",
    "                print(f\"Episode {episode} reward: {episode_reward}\")\n",
    "                print(f\"{episode} Average episode reward: {avg_episode_reward}\")\n",
    "                with writer.as_default():\n",
    "                    tf.summary.scalar(\"episode_reward\", episode_reward, episode)\n",
    "                    tf.summary.scalar(\"avg_episode_reward\", avg_episode_reward, episode)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "LkkG5Nhtvvnn"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Create new threads\n",
    "    thread = Publisher(LAP,LAR,LHP,LHR,LHY,LKP,RAP,RAR,RHP,RHR,RHY,RKP, rate)\n",
    "\n",
    "    # Start new Threads\n",
    "    thread.start()\n",
    "    listener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "oo9fuaJ2vvnn",
    "outputId": "918f3f8d-1e3b-45d4-bed0-93dcdba8853e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listener\n",
      "Episode 2 reward: -130.14558803177573\n",
      "2 Average episode reward: -130.14558803177573\n",
      "Episode 3 reward: -127.69182702454583\n",
      "3 Average episode reward: -128.91870752816078\n",
      "Episode 4 reward: -127.75112661801694\n",
      "4 Average episode reward: -128.52951389144616\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2-P_nmDDxUr"
   },
   "source": [
    "#منبع\n",
    "https://github.com/shakti365/soft-actor-critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6358550df0>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2dd5gcR5n/v2/3zOxKqxysLMuW5ByRbMsRHHDkcCAZOAzHHT6MCYYj2HBkG0wGw9nYP5MMx5kznDHghOWMs+QoWVawrJzDrjbPTHf9/uiu7urqqp6enZmdnZ36PI8ezfb0dFd3V7/11rfeeosYYzAYDAZDc2HVuwAGg8FgGHyM8TcYDIYmxBh/g8FgaEKM8TcYDIYmxBh/g8FgaEIy9S5AWiZNmsTmzJlT72IYDAZDQ7F06dJdjLHJ8vaGMf5z5szBkiVL6l0Mg8FgaCiIaL1qu5F9DAaDoQkxxt9gMBiaEGP8DQaDoQkxxt9gMBiaEGP8DQaDoQkxxt9gMBiaEGP8DQaDoQkxxt9gMDQkz63bg1XbO+tdjIalYSZ5GQwGg8i7fv4UAGDd9RfUuSSNifH8DQaDoQkxxt9gMBiaEGP8DQaDoQkxxt9gMBiaEGP8DQaDoQkxxt9gMBiakJoZfyI6hoieJqIXiWgJER0vfHcNEa0hopVEdE6tymAwGAwGNbWM8/8ugK8zxu4lovP9v99CRIcBuBTA4QCmA1hMRAcxxpwalsVgMBgMArWUfRiAMf7nsQC2+J8vBHA7Y6yfMfYGgDUAjlf83mAwGAw1opae/1UA7iei78NrZE7yt88A8LSw3yZ/WwwiuhzA5QAwe/bs2pXUYDAYmoyKjD8RLQYwVfHVlwCcCeDTjLE/EdG7AfwCwFkASLE/Ux2fMXYLgFsAYOHChcp9DAaDwVA+FRl/xthZuu+I6DYAn/L/vAPArf7nTQBmCbvORCgJGQwGg2EQqKXmvwXAm/3PZwBY7X/+C4BLiaiFiA4AMB/AszUsh8FgMBgkaqn5fwTAT4goA6APvnbPGFtORP8L4FUARQBXmkgfg8FgGFxqZvwZY/8AsEDz3XUArqvVuQ0Gg8GQjJnhazAYDE2IMf4Gg8HQhBjjbzAYGg7GTOR3pRjjbzAYGg7X2P6KMcbfYDA0HI6x/hVjjL/BYGg4XCP7VIwx/gaDoeEwtr9yjPE3GAwNh2Osf8UY428wGBoOI/tUjjH+BoOh4XDNgG/FGONvMBgaDmP7K8cYf4PB0HAY2adyjPE3GAwNh5F9KscYf4PB0HAY2185xvgbDIaGw8g+lWOMv8FgaDhMeofKMcbfYDA0HMbxrxxj/A0GQ8NhZJ/KMcbfYDA0HCa9Q+UY428wGBoOs5hL5RjjbzAYGg7HrXcJGh9j/A0GQ8NhNP/KqZnxJ6KjiegpInqFiP5KRGOE764hojVEtJKIzqlVGQwGw/DEGP/KqaXnfyuAqxljRwK4E8DnAICIDgNwKYDDAZwL4EYismtYDoPBMMxwjexTMbU0/gcDeMz//ACAd/ifLwRwO2OsnzH2BoA1AI6vYTkMBsMww3j+lVNL478MwNv9z+8CMMv/PAPARmG/Tf42g8FgSIUx/pWTqeTHRLQYwFTFV18C8GEANxDRVwD8BUCe/0yxv/JJEtHlAC4HgNmzZ1dSVIPBMIwwxr9yKjL+jLGzSuxyNgAQ0UEALvC3bULYCwCAmQC2aI5/C4BbAGDhwoXmaRsMBgAmq2c1qGW0z37+/xaA/wTwc/+rvwC4lIhaiOgAAPMBPFurchgMhuGHSexWObXU/N9LRKsAvAbPs/8VADDGlgP4XwCvArgPwJWMMaeG5TAYDMMMI/tUTkWyTxKMsZ8A+Inmu+sAXFercxsMhuGNsf2VY2b4GgyGhsPIPpVjjL/BYGg4jOxTOcb4GwyGhsPY/soxxt9gMDQcRvapHGP8DQZDw2Fkn8oxxt9gMDQcxvhXjjH+BoOh4TCqT+UY428wGBoO4/lXjjH+BoOh4TADvpVjjL/BYGg4jONfOcb4GwyGhsPIPpVjjL/BYGg4jOxTOcb4GwyGhsM4/pVjjL/BYGg4jOxTOcb4GwyGhsMxxr9ijPE3GIYBv316PS695al6F2PQMJJ/5dRsMReDwTB4fPnPy+pdhEHF9a2/RXUuSANjPH+DwdBwcM2fyFj/gWKMv8FgaDi47GNM/8Axxt9gMDQcoexjzP9AMcbfYBgE+osOvnXPCnT0FOpdlGFBEOppbP+AMcbfYBgEbn92I255bC1ufuz1ehdlWGBkn8oxxt9gGATW7+4BAIwdka1zSYYH3PM3ss/Aqcj4E9G7iGg5EblEtFD67hoiWkNEK4noHGH7AiJ6xf/uBjLD9YYmYEt7LwBgvzEtdS7J8IBr/sZ6DJxKPf9lAC4B8Ji4kYgOA3ApgMMBnAvgRiKy/a9vAnA5gPn+v3MrLIPBMOTZ0uEZfzJCRVXgM3zN3Rw4FU3yYoytAJSxthcCuJ0x1g/gDSJaA+B4IloHYAxj7Cn/d7cBuAjAvZWUw2BIwnEZ7npxMy46ZgasOs0K4p5/rbNRMsaaIvY90Pwb/Fo3t/di3a5unDxvUrDNdRl+98x6tPcUMH5kFu09BXz0LXORtaur0tdqhu8MAE8Lf2/ytxX8z/J2JUR0ObxeAmbPnl39Uhqagt88uQ7f+Nur6Cu4eN8J9alHe7rzAGpv/F0G2I1tD1PBZR/W4Dl+zvzBI+gruFh3/QXBtrW7uvCVu5ZH9vv3N8+t+rlLNiVEtJiIlin+XZj0M8U2lrBdCWPsFsbYQsbYwsmTJ5cqqsGgZGdXPwBgb0++bmXgHmqtE5I1S7ZLfh8b/Wr7Cm5sW38xvi1bgxa9pOfPGDtrAMfdBGCW8PdMAFv87TMV2w2GmjEU7KFFgIPB8PyTj/+7p9fjP/+8DK9981y0Zu3EfYcyoedf54LUAFey/VmbaiJv1SrU8y8ALiWiFiI6AN7A7rOMsa0AOolokR/lcxmAu2pUBoMhQj3l4cDzr7nmn/z9Tx5cDQDY19vYk82K3Pg3vO8fR27Aq631cyoN9byYiDYBOBHA3UR0PwAwxpYD+F8ArwK4D8CVjDHH/9kVAG4FsAbA6zCDvYYaMxQMBB9nrrfnz4ZJQjRnGHv+sjSYqVGQQqXRPncCuFPz3XUArlNsXwLgiErOazCURTAbtH4Gj597MAZ8k3CGicfsDhPNn+O6LIhE45JWzraQd1zkMkPQ8zcYGgFuIOrp7Aaef50HfHnjIOvKjQaXfYaL9RfrBW+gW7KeeR6Sso/BYEiHNViafwmjzr3KYoNbf3eY9GA4Yr3gDUFLxhuQN8bfYBggbAjMBqUhovnz7xvc9g87zV+sF/zZtAaef21qrjH+hmFPkP13CIxxFutu/Hk5Gtv6h2MXw4OiwvPnobjG8zcYKqSeA7781XZdho17enDHko01OU+ptiXw/BvcZQ4meTX4dXDciOfPjX9tNX+zgLth2DMUBnwReNwMl97yNDa39+Ltx0wPdN1qkVb2qXUPpNYUh7Pnz41/oPkb2cdgGBBDwcsVPe52P81EXjGNv1rn0X/v/V/rsYdaM9xm+IrPLRjwNdE+BkNlhJp//Vx/0ejyuG1VDpdqnUf/PQvK0cg0evlliirZx/f8TZy/wVAh9VR9RKNbU+NfwigyQX5qZETjPxx0fzdhwNeu0QxfY/wNTUM9TQQ/t2j8+wqO/gcDPU/KiyzVSAx1xElRw8D2KzX/Fr+e1MppMcbfMOxhQWx7/awEEwZauYbbr0jnWylpxzeGledfx3JUi0icf6D5e55/ra7PGH/DsCfwuuvoIoZpFRhyvvHvK1bf809r/Bve8x9msk/SJK9aYYx/Snb7C4IYGpd6DhKKIZYtNZR90l6i8fyHFuKkOzm9Q60wxj8Ff3huAxZcuxivbdtX76IYBgB3DOtp/HkZXFbbAd+0XnA9e0HVwK2B5r9hdw8eX72zOgcrE3HCtTzJq1Y0lfH/09JN6O4vlv27nyz2FsDY2139BTCWrt+LQ798X7DGq6H68ORf9TL+okEuitE+dfT8HaexjX8x4vlX51pO+97D+MAvnq3KscpF5fnzaB8z4FshyzZ34D/ueAlf+NPLZf92S0cfgDAtbzW56ZHX0Vtw8Ny6PdU/uAFAaPTrNdlLNMii5l+bOP8m8fzd6nv+4fEG/96Izy2M8zeef1XgKXVXb+8a8DFq8cLwh24Phaxjw5SiU9+UBpHZm0K0TxrNv9yeamrj3+iafw0NdC0a5VIUnWgdAULP30T7VAjvarf3DlxeqcULExj/Gk3kMAie/xAw/hHZp4SRufXxtTj8q/djx76+1OdKaxMbfcBXNJbVbgfef+sz2DXIAR6RxVz8jy1G868O/AVs7xm4bl+LF4Yf0jj+tYM/t/pp/uFnlwmhniU8/589vAYA0FmG998soZ6RAd8q+8ZL1+/Fzx95varHLEU01NP7bNXYKDSd8a+kS1eLF2awHnQzw1+seunc4mmjA77JdZE7KuUUuylDPatwKbJjUIs5GGnP70hqgBnwrZCBen1ypEYS2zr6MOfqu/Hk67tSH583Sm/s6h5QJJKhNDySol6evzyYxxfqTjIwEWNQRrmTPH+mGFRsVKod57+vN6oI9OYHV/dXPe9ajwM2jfEfqHdQzkv4zBu7AQC/f2ZD6uPzl/Wrf1mOD//6uQGU0FAKp86yT1TzdwMjnOT5dwmOQDnlTopUEZ2Xoez5v7ZtHzpKyLPR3D6VX8uenuhYYHtPHj98YNWgOWRK2afG44AVGX8iehcRLScil4gWCtsnEtHDRNRFRD+TfrOAiF4hojVEdAMNUp7dgb744s9KHYMPQon5t59YswuX3PgECo76RRcndzzzhgn3rAXc0NUr1FM8q+uGjkiS598vfFee56//LhJRMoRDPc/98eN4x8+fTNxHnKdQjSvZK82zefC1HbjhwdX41RNvVOHopVHKPr5pHKrRPssAXALgMWl7H4AvA/is4jc3AbgcwHz/37kVliEV4otfziIacpheEvz7jNBif/oPL+L5De3Y3aWOMhoKC40Md/hzKQ7yxKb1u7sBAEyobkXXDcefEjx/sY6WY6iT5Jy84IA4GmdkqLBmR3JIdrWzevZqBt95uGWtUebz9889pjVbk3NWZPwZYysYYysV27sZY/+A1wgEENE0AGMYY08xr692G4CLKilDWkQjW85gTjnGv+C78RnB8+cDzBnNUmzyi/2npZsifz+xZhc27ulJXd5moa/gaKNlGGPY3N4b/M2N/mB6uw+9th1v/t4juOeVrdIqTaF33pfghESMfxmLrSdVUbH3OVRln2LKRimyWw0GfDltLYOz0m1kXIh5E0pPmjsRV593CL554RE1Oedga/4zAIjWbZO/TQkRXU5ES4hoyc6dleXcEJ9toSzPP/ycXvYJDT3vvus8fPmQ/3HHS5G/33/rMzjzh4+mLe6A2d3V3zC5i/oKDg758n3419+ox0j+uHQTTr7+ITy/YS+A+sT5r9jaCQB4eVOH5ECEnv8Gv2egIuKll6iuLKX+LRr/odrjzKc2/uF+Yqjnk6/vwkX/pZdZRTbs7gnqiO529OQHJ+pHluRsi2BZhI++eS7GjqyT509Ei4lomeLfhQM4n8r91dZCxtgtjLGFjLGFkydPHsDpQpwBDnbJE3SS4BUuY8U9f53zlvSy8u9qsdarfJ4F1y7GuT9+vKbnqRZ/eWkLAOCJNbuV3z+91hs7WePP5uY9ssFUfXiYnsuiUeiOi6DGv7SpAy9tbFf+XnzmxRKef3QeQfx7x2X44QOrcMXvnheOWZ2b8fKmdpz9o0dLyjRpSVvXdaGen//jy3hxYzu2dZSeGHfa9x7GJTd6Ywu6xrA3P0gDvnJE2CAMhZbs0zDGzqri+TYBmCn8PRPAlioeX4v4cE++/iH85sPH4+R5k0r+TtRrS8kGBYXnH2SU1Pw2qTcxWF7HC4IB6ugtYOyI2nga1YLPeD1k6mjl9/KknzDaZ/B0bj5Y57gsFuop/r16RxeOnjUukLC4zivORylV7IjhUNSzDXt6cMODqyPbqtULuvjGJ+G4DCu3dWLefqMqPl5a4+8yb2yt6EafNreZ5XZseB354In74x0LZmLHvn78221L0F3Dd5BpJGXHZYMy439QZR/G2FYAnUS0yI/yuQzAXYNxbvEFKrosdYK3yLTrEl1Jrleq9H1dFsWkd7CzL+p1LF2/Bz97aLVm75DdXf24Y8lGAMBX7lqGT//hxcT924Uwtw27h/74wl4/DLCUd8QlhEDzH0TZh4fp/eIfb+AmYbaoN+AbpuvlvcVDv3Ifjrt2cbBfOZ6/ahUoEZWOXg3Pf+Oenqrf07STMIuuG7xnohEl8AiZ8srFL+M9x83GUTPH4azDpmBMawa9NTT+ujByh7FByfVVaajnxUS0CcCJAO4movuF79YB+CGADxHRJiI6zP/qCgC3AlgD4HUA91ZShrTIL4U4IJj2dyVlnyDax7utqkWZZZJkn86+aKzzO256Ct//+6rkAgO46g8v4nN/fBnrdnXjtqfW484XNieXW2iY1iXo0EMFPvNVa3j8zR290f0GM8BFbP9/9cS64LPLvOLxFA/c+DMWTeMgGn+VQe/sK+Ch17Zj456eiJf7oV89h017ow24XG+JquP5P7IqHIcr1UClJa3xd93wPVNdSbmeP7/HgmKLkbkMemoo+zgaz1+cCFhLKo32uZMxNpMx1sIYm8IYO0f4bg5jbAJjbJS/z6v+9iWMsSMYY3MZYx9ng5Q/VTa+SWe9/dkNgQfsluhSi3APi8s+x3/rwfD8mpctyXMqJ6eLyI59XlKqtLKRONi0bEsHfvbQ6mAgbCjCeyoOY2CM4dv3rMCKreFgNb9ubvy5YRrMQU7dy8tDPfn6rAVNj1A0gnKI6j2vbMWRX/s7PvzrJXjrjx6N1W2xsQGideyYWeMCuaRSlm3q0JaRwxjDr594I/VKeGKjl2Qa+KCot1+4Pa3DvEVw/r5732tBYIbocY9ssWsqvSZ6/kPd+DcSqoqk2taTL+Lq/3sFl/3yGX+f8LtSLwz/nr/4YmZAneFJGkfgsk+mzIrAu8NpvRbRa7v50bX4/t9X4UcPlO5h1It2waPv6i/i5sfW4t03PwXHZVi6fi/W7vIGHzukHsJghjfqJClvkle4lKMuKiWfEJlz//Jtwee+ghtzIOTqwq/75g8swB8/eiIsoqqEvW7Y04OpY1r9c6ivY3N7L77211dTz14Xr1tneBljfmpsvcRT6upOuv6h4PONj7yO25/1ZFJxzunIXOXGP190tdKR1vi7g5Prq2mMv+od29cbNY7rd3dju+8180kfkYdSIlxE7MLHz6/R/JM8f1/2yWWsstZ75Y1FR2+6DKbc+xwtxDQ/v35v6pjrwWYv9/xdFmi1vXkHj63aiXfc9CRW+VE+PH13MMN3EI2/ynPzPG4XrhumGNeFHYurfMmPoUsaC5KdGNFwLNvcge/d/xoAbzA5Y1vIWFSVlbw27OnBgZPbAOgbVl60l4Rewq2Pr41JUxzR8+/S9Hz5qYJ7LHr+Kcqtcvp4T0t8biOzlcs+//LrZ3HoV+5TfiePQ4bbGexBsMxNY/xVnrc4hb4nX8Sbv/cIPnLbEgDhrLroBJ34MfJFN5gaHiwa4rDIsYEE45/wDvKXvCVjRSZ6lVLK+CSzfX3pjD838tPHjQi2decdLN8yNOP+RY+el73ostj1tvcUsK2jr6q5fRhjsVQAKlQDdhmb4Liep5q1LBCl8/xlr1qWA+XrEr3XS258MgiJ5U6BVQXZ57+fWY/N7b2h8dc0JvL1bd/Xh2vvXqHtCYjGXw544IQz6ZM0f/31qS490PyFxzYiZ1c84MvvvSqQQnyusp0Z8gO+jYTK6xNfMP6QebwyD3cU61A0ttj7fNUfXsCx33wAjLGgojuMxdYN0E/yKi375DIWXhU0bca889+3bJsyNC7w/FOuXcAHqqeP87rwp873QmB5orqhBGMsIvsUNV1nwMuVtOjbD2KrH/Otarz7Cg427O7BrY+vTdVT+u3T63HsNx/AG7uSB8ZVmn/WsvxJXt73WdtCXmM0kwZ8Zc9frtqi1yheM/dqMxZVNP7hugxfunMZAGDW+JEA9I2Y+Hw6egvBeXX3Ou+Exlbn+QfG31Zp/qXz4aicgND4h8+tzdf8t7T3Dih5nJgU7pFVO+LlEINJhHrQEAO+jYSqtecv2J7uPH7xjzci343xjb9Kl3t+w14ccM09eG7dHtzziqe/tvcUguO5Lovl8qlE9slYFl4UYvEdxvDSpg589HdL8fW/Lo/9zg5kH/XL09lXwM2Pvh68sNx7njrW8/wPmzYGB0xqwzNrK080t7OzXysfuYLnnpbO/mJEw1elLPj8uQfj+DkTYr9VPYNr734Vp33vYVx79wrc6C+eksRjfoTL6u2difupuu2e5+8NUhO8iJ+C4yoNSz5hwLc7Lxt/yfMXxA/RhPB6YVfo+YuRcqf4joKufotlF9Mm62xp9LrVdUPOdy9q/vx6k2y1quHjpxKN7ohsBqt3dOGk6x/CwyvjxrsUr20L64jKWRA7dI7s+RvjXz2Uko3/xD/0q2dxo7Ryz5hWT/9W5fZ5dKVnAJ5Ysyt4SFs7+gLd0GEs0KXl38okxvn7nkPRdSMzQV2hW/jfz2zA1dKcBf4CiTKI+CLd/uxGfPve14KMhfwFHZnzIlCytoXj5oyPTP4ql47eAm565HUcd91ifPp/vZQVW9p78ct/vBF0gT/3x5cx/z/Li/TlPbSs7XmvqrVPLz52RiBHiKiewbpdYXc8zSpvLRnvHiXl5QGiBpiTtS3f+HshhVmbUHBcZUqD/jI8/6QBX9GTFY3/QMc/trT34tTvPgwAuOOjJwYTu3SNiShtdPYVg+elO7t43bu68vjCH1+ORHIB8QSKKkOf1LNRfccbYJ3cMpD5L0+v9XrOI7K2MrGjeG+cyGcj+1SVJO/qZWEwijM60PzDbbyC8wrakrHR5hvMrR29YR4fl2F3d1rjr+iC+vtybbmn38EyQX933ai3c/tzGyO/75ZCHXmZf/bQaqzZ0YkJbTkACHotYUK6sMKNb8tpu90qnt+wF5f98tngHvzg7yvxnfu8gca/vrQF2/f14Z03PYlv/O1VnP3jR/Hte1fgT89vAmPAwmsfSD3vgmfCHJG1UXRc6QUKPcKs5HofOKktdq9/+Y83sF1YH5dHCSXBZ+CWGoBXPdesbcFh3gxfiwgZ3/NXxbZHJ3lFjyVr/vK5RO9VtCHcWNo0cM//nle2Bp/nTR6FrJUctSSGsnb2FbTnXbOjE8++sSdyL17e1I4/LNmI834STTui0vz7Cg5WbusMXP8k458s+4TbRAeinHeBc++yrTh29jgcOm00dnfHQ10jnr/w2WVG9qkqqspQcFztYg1hDHHcs+Qvfi5jYZQfIbOlow99hXDFKHlQ0GFM6W0pu6D+Nh551NlfRL7o4uiZY4PfiBV4tJR5kEcoiKGmnX1FfP/vq3Dxfz0ZNBuvbPYaPe6NXXKsl3njwmOmI2tZqZJjcT74i2fx2KqdwcC0mN8IAP7pp/9Ae28B08a2oq/g4uZH1wbf7erK4/5l21CKHZ19+KXfW2lrycBlUeMiGgXR+P/nBYfiwMltMfnkG397Fat3dMG2CO9eOBMvbGjH2376OJZtjjsDHD4zt7+k8Y9vy9gE1/W+IyLkbAv5IlOmdo6EekoHk8d55ChL0dtXfbZtQtFxg9j7ciLJVvlyVy5jYXxbDpZFIEqSfaLRO/xvudqf9cPH8O6bn4pcW3/kc3x9A+6suC7Dp//wIs758WPB+7y1vQ83PfK60ulTRaXyY4qD5R9981y89JWzMaolE3PmSpEvuli2eR9OnT8ZE0e1KD3/6CSvaDqPQbD9zWP8VXasv+hipUa7dVzPwD6+eldkG/8d4EXh8Mk6yzZ14B9rvH0dxgJd9psXHg4AuOWxtTjwi/fg3le24phv/D3wJFSeED/Pjs5ocqpjZ48Pji++bHMmeR7K2p1dcF0WvAC88QBCz6Uz8gL62rn/90FTRmHd9Rdg/pTRyNgExtJHyHBvtKO3iL6Cgwlt0fxAOzr78YET98c7F8xU/TxVPqEP//o5/PrJdQC8SIyi60YMOr+XNlEkv9LbjpoOi3iYpbePaFBHt2aw/8Q2FF2GZZv34dq7X9WWIfT8kxtGVaMehHr6mn/W9v4WDRt/FqIR3N2dx08fXB2Jbko6l2g4Ip6/zQd8Lfz5xS1YcO1ifOueFTjky/elimACgJc2duDU+ZPw8lfPDrZ5joK6noj1p7OvWDJrZ15j8HcIdVns4QHAqd99GPf6zgN/Nz/+++fxnftewwHX3INbHw8dDUAtAcfCR/3PY0dmMaEthz1lGn9e9tEtGUwalcMulfGP9Fqj5TNx/lVE9TLmiy5e26ox/ozhJ4tX4Rt/Cw1BKPv4nr9tBUb1D0tC6cV1WRBHffDUMQCAR/xxgq/9dTnaewrBgKEqzpuXdUdnWOFHt2Ywa4IXWcHcsCzjRmbRV3Cwblc3zvjBo/jJg6vR3e+VT5Q0xB7Ozs5oF7TgT5gRvZ6sndydFxGjivZ253HKdx5SpqFoydi47MQ5OGBSXI+XU1moWLUtlGXachm4bihZAeHLZNtR2SdjE2yLsGp7Fz5x+wtwXIYbhBxJGYuCSVdAsmEf4Rt/3eIfHFUvL2tbXnoH5hnorC/7iOfjkl1/0Q3O9ePFq/GDB1Zh8YrtEWckuG55wFfj+QehnoJdueUxzzBu1MTdi/QXHazZ2YWjZ46LLHKS8XsSKgqi8e8vCo21urEQx8rEHpFYl/n1Zi29+RITsnGHIfh9StmHMxDjzxuxXMbCxLYW7Onuj9WJiMGPeP5mwLeqKEM9iy5WanLYuy6L5C4BvAkzc66+G6/4YwQF140t/Ax4mRo3+PJHVkryFiae8lB5TI7L0Jt30NlXDGSlMa3ZIF+M6PmPasmgJ+8EPZh7l20NDJNYYUXj/wNp9m7RcWMyDS93Gm14U3toOPb25JVeDuC9WJNHt+Cuj58cbHv6mjMBpNNURa9R5fnzrzOS5i9+vm2Zv6YAACAASURBVPvlrVi8Yjt+vDg0/rZFQQ8OSM4vw2Wf0pp/fJvYoFrkh3oWo3NCjv7639Hek0d/0cGIXHQVqfaefGR2b3Au6WS2RvO3/WcsP2sAkRTIvXlHGYq5bpeXyG3+lGj2zqToIbFR8DR//URIIBpJJD7v7fv6sa2jDwuvXYwn/AYwrYHctLc3SAMOaMbZgtw+8WNObMtpV+LTwcuey1iYOCoHl4Uz09fs6MT8L90TiQCKhCybaJ/qoqqbBYdhrSZe23EZ1knfcY18tT8XoLu/qDQUT76+G3cs3YSMRbGHKC88reoGu24o+cwc74VfjsjZkRzx3PiPbs2Gg10A9nR7FUz0ZIFk41pwWCwTKTcQOo/uhQ17A+9GNBxylJMIj2AY05rFgZPacNVZ8zF1bCtaMpZ2Qo+OtpwNl0XLx8tjW4RsJryenG1FyrVeSl6XsazI/eovOLjtqXXY251HT76Ip16Pz3cYkOwjNKhEQDajHvDd2dmPvOD5c7r6HWzf14fZfg8wPFf0POKTjET7UDjJS2b1ji78aekmMMbwL79+Fkd//e+xRoXr/fP3i6bSztqWNr2DaNS6+oqBsyMeWWxIN+8Njb/o+a/Yug8vb2rHrq5+fN6PblNlz9U1Kp/8nxeCz0rPn4d6KuSWijx/28LEUS0AEIyx3LF0EwoOw0d/tzTYX6wDjmtkn6qiDvV00F9wlXqzy4B9JQyS7A205ewg1wngGSHZ+IsvlFYnZSyQfLjxb8vZQXfedUXP30avYPz5IO/cyVHvLClHSdF1Y9Ex3PNXlfHFje24+MYnceMjXlz8FsH488aHc+P73xR8Fo3OQ599C6466yAAXgNW6l7LjMx5PSLxpenq985t+4OpnIxNEalLTuuRsaOyz9pd3fjKXcvxydtfwJf/vBzv/X9PB44AN2YlZR9VtI/QoHoDvuTLPtFj9RVcPLFmV6wB7+4vor23gEmjcpHt8VBPjecfaP7hxhveeyyyNuF796/Ef9zxEh5bvStYDOeptbuxtaMXV/xuKTr7Cli9owsWIRZGm7EoVZx/JNRTuD+iYd3Sofb8f/bwGvxRWuJUlfMqTQirqqxJoZ6TR7dgV1d/zGlIQpR9uH3RzbjP2oRHVu4MJFbXeP7VRRfqmXfcIFxTJM0MyE17o+GJlmTslcaf8cqvX7LOcVmggU8e7XkNUc8/NEKjWjLoLTjYsKcH08aGDc97j58VOeZVipz+/AqLDou9SDxFhMqje+4Nzzjwl3Zrey8yFmHSqByeXx/NBio2KjpvZnRrBmt2dOLC/3oCi1/drtxHHhPgcxJEw9nZVwRROHs2uBYravzl1Bu2RUH8vsjrO7qwYY/3wm/zNWduXEqt8KTU/DNhgypq/rLnf8fSjdjbUwiCBngj0N1fREdvAZN8TzI4l1RXr7tnRTD5T6n5+/+/9/jZePvR07Hf6LDeLNvcgZPmTgQA/PmFzbju7hW4d9k2PLhiB7a292K/0a2xRc0zFmkdGbH+dPUXgzEacW/Ridq4R/D8/ed0wZHTAAB/l+qGrZCv0iSsU+beYjzaJ/7de46bhZaMhRseLD0JkNMvGH8u3Qa9W+n8lx43G7u6+vHoyp24+dHX0dVXNHH+1UTV2ueLXpy4apHmNFEudwsxz4D3Eoj10bYo9hDF4+pWLXIZC2QFPtO4LZcJBqMcSfZhzDMMR8wYi8+dczC+/LbDcMCk0qsq8TQRBYfFPH9uKFQ5W3j3f/+JbXBdhqfW7saUMa3Y3Z3Hs+uis4JzgveqS1Y1ujWD59btxUsb2/Fvty1BwXFxyJfvxbtvfirYR+4ZcOMvGs72nkJQblESIKLI7+X7Lg/4cvb05IP5HvzF5Y1uV380L1Q8tDd+nRkrqvln/PQOcqgnTzd8/TuO8nLv+4aps7+Ijp5CICNwVI4KT+usmuQ13l8Tlt9D0Wl4ZVNHsN8dSzfhby97dTzvuOgpOBjZEm8kM7alH/AVkgZu7egVPP9wn12adM/8vlxz/iH4zFu9XmLWJpx16BQAXq9XJs17mzbah7P/xDbMmjAyMSjBdRnufWVrIK+Kmj+fMKqTNudMakNr1sJX/7Ic3773Nby0qQMJY9lVo2mMvzK9g8NQKDKMVBj/tItTjB2RxaHTvIge2dhn/EWYdeWQPVDOva9sDTzakVmvbCNydvAiR2QfXrH6i8hYhCtPn4d/PeUAjG9LtxRjwWGRVZE4umifnnwRq4T1Wu98YTNe2NCOqWNbYw2Idxx15InI6Nbo/V947WL0FVw8+0bYkMie9Ahf9hE9/z09+eAcqrJwZE/bljR/Tl/BFV7caHpocQD93B8/jmO/+UDkt6qeZlbS/HM2oVB0Y/WA96iOnzMh4lVz2UcOo00yeBHZx//jytPnAQDm+7NzpwrGf9mWDuXxtnX0oTfvBA2GSMbWD/jyKJbp40bg6bV78OcXvYWFxPvDDSYPi+ZwA5qxLBzpz3EpOAz/77IF+L+PnYTTDoqv652mx67W/Hm0j7qOqq7RdVlQ9u/evxJX/Pfz+LmfKYA7GC22FbyjunG384+cihMOmBgZ7DayTxXRRfsUXFfpQeSL6eLbL/W7hIBXcayI7GNpPX/GmNbz/9pfXw1W3+KV2fP8wwFf3jiNbgmNk1hhJrZFvUMdPGImLvvENf91u7px2FfuD1JNFB03iGr67juPwp0fOylyDIuikSVJOe4B4JJjZwBQJ/2SX1iV57+nOx9cR04y/t+88HBM9Gc2899w+SRjEVqy6ldB9vx5OVZs2xeUc8OeeJikOs4/Hu1TcNyY58+XqWzJWJF7trXdy1Aqj1ElObviY+Wa/3FzJuCpa87AuxZ60qDo+W9u70VXfxGLDpyAl78WxvLf/uwGrNnRFTgj0euihKye3vafvu9Y7D9xJO5+eWtsH35PT543CYs/82b87H3HAgg9f9siHDF9bLA/EeFNs8crDWQazz9pYqXO5mYUkx6/9/eVOOKr92NfXwEv+Isf8aAQUfPndWjZ5g588JfPRrT/j58+D9PGjsAh06KD6GbAt4ro4vyLDgsGD0XSzm5tzYZavMrz10X7OK7e+AMIZspyD0nW/Pn1cD2xr+BGDPh+o9MZ/0LRS44Wl33inv+rUo6VosvQ3pPHmNYM5k4ehcOnj8Unz5gXOYYtyWAqVvjhtu8+bpbye34uEZXmv6c7H5xDvp4PnDgHf7rCa5wCr8xvtL0B37gDAIS9ktd3duHHi1cF5djXW8DPH31d+RtAPakwiPZxGMg3/kU3nv57T3feazj93PucN/wBx3EjogO+Sd6uSvMHgGljRwT3iif0Azw5ZvX2LmQsC2Nas1h93XmYNCqHLR192LCnJxZ+6h03IdrHCRvaDyzaPzyPuI8wM3vefqNwyjwvWRy/LxmLgrGvhfuPD35HCgOZZk6izvMnUh8TCJPwidzlO2j7egvBMV/c2B5x7HIZCyOzNoi8PFyPrtqJFzaEObO4syjPWTCefxXYvq8P8790T0RCALybm3ccFDQDvmUZfx5CR/EB35js44bGPymenGv+syd6kRWHTB0ddOG9mZ5R2cc7n+BlayoPH8zjFFwXRTce6inH+S9Ztwcf++/nI/vkiy729hQwvi00Rp9+60E4+7Apfnkoml5AU6bDfNnsmFnj8MXzD1HuIxs4PugY8/x9oy/PrwBC48uNSmD8NZo/EE7quu2p9fjx4tV4YcNejB+ZxYL9x+PJNfEJV7ryAmFvpOi6/gxfC/miG4vE6ugtBI2ReM/4oPXYkVHPX+d1A2rNX4Z7/odM9bzP3oITaUTFeRsq2SebIPsEht2mIKcUgIj1FyfnieXkz5bfg+e//Fb89l9PCH43UPOojvbRJ3UD+ES26O/4X+LKaB29BWzf1x/R/C2LMEpwMMV7mNE4K2bAtwo8snIHCg7Dg69FU7Lm/Bev4LBAPxZJ8spFRmStqOcvvGAZOz7gy41CsZTx9w3UO940A//zkUV4z3GzgheZCQO+4mC1LN2oUinIvZyi43n+8Ule0Tj/L0iZQ71rcLG3J49xI8OXmoiCGbwZ2fhr6vNN71+ABz59GlqzNs45fKpyH/nF49cqh0kGmr/CmPNrFCMxAH20DxAPzyu6DLZlYdGBE/HK5g5t+J5K8xelNIuAXMYL9dyjmBuRExomGVn2Sbtim86gcM3/6Jnjgm1i4/nzf14QfFZ5/naC7BN69RSLElLt4/3vXTt/B/n2CW25yPkHah91sk+S1JKxrchsZfE4cm6jnnwxEucPIDKJUNw3WGNBclZMYrcqoJtt6qXT9QxfTuElyp6/rCHzZyPKMbLMow719P4vJfv0FRy0Zi0QEU6cOxEk9CpcFspHYlI3W7qO6y85En/7xCn450Wzg22y51ZwPOlL9pRFQ8UYwxRh/gKn6HiL1oyXPFH+W9uW7ofm5Ro7Mov5UzyvUzsuoMlcKTeggSelCJeQPcrQ87e0mr/8jBjzopYOmjIaLosuYh5NAhg/VkZoUEXNXzV7tEVomIBo/RM1eiBc0F6FHH2mgh9PHPgV9z33iKlY4Mst6gFffRLAojBo2yrcY/Fpyrl65OekK7cqbXYaVJ6/47LECJusFU9hwR+3N9kwPGZfwY3IPkB08qM4jqZ6voDx/KuCbtGNXMZGf9H1UhsoIkPkFZbEkMXPvPWgwEi1Zu3AEFkWRULYbIobf45K6xXpK7gxTykI9XSjoZ4cVaz+ETPG4r3HlzD+boLn77o44qv340l/luvxcybg8OljMCJro+B46xaMHxnVoLn8ZFM62Sf6W/U+8gsre/5cmw/livhx+LZQ87eD3+hkH7keMHiGjJ//fbc+I+wr5GdRTvIKG1QKjD/D7q7+2GzenGT8J49uwe2XL8K9nzoV+0+MTrJS9Rw40Qlf6ns7ZXQr3n/CbLz1sCmCIxO9H/z+qsbHsrZ+khc3dFk76vmLDSU3nBnBiQKimr+Kcu0jP6eqqKVm1WYVDRw/Do++43Wor+ig34kaf91i7dzIy57/kvWVL6RUioqMPxG9i4iWE5FLRAuF7W8loqVE9Ir//xnCdwv87WuI6AbS1cgqIa6mI9KSCWUfVVig/KD5w3nT7HH45Jnzg67qiKwd5NyxKbo8nirOn+O4bklpqTUjG3/u+Yeaf5sQqaQznKJXIXfbvdWwVOkdwsFJniTrgqOm4X8/eiLu/uSpaMl6g3wdPQWMkz1//7dE0XkPaSIYkhpL1X5y5E5g/BXGPOb5Z0XNXy1JyM+o6LjKsRx5X10+f8AbZyHyNX/Hxe7uPCaNjjaggedPYWO26MCJQVixiDi/QSbNPbcswnUXH4kjZowNc/5Lx+Pyokq6sa24JMIput79IpKMv7CP7PnzNNG84dB7/uXBz6N6NkU3eQEVlebPr6LoetF3YfCFI4R6xu+XODgeyj7R+nruEWr5s5pU6vkvA3AJgMek7bsA/BNj7EgAHwTwW+G7mwBcDmC+/+/cCsuQyMdOnxd4fGIlymW8F6/gukovUTb+/MWVjacY7WNZFPEqMjZpu5JFV53XJ3psWWoKjT+vwJHsipqXRGzcdJ5/PL1DPNpnsjC5KGNZXvK5/qLC8+fliL5QCaH3AbKx6ugp4IzvPxJZyUw8B/f8eRinLtSTlxmID/jaFkV6diLyM+ovutpGvZTx5y94mNXT0/x3dfbHIniCXomtHhAU2dudjw6mCpRrIPl55LrE76dywFchiXCKQobKERHPP7qPd05hQmAQRKHvsZTrNvLz6HopScfL2lYkgywQXoPjMrgsbCD7FbKPiHh+7nSJ0vND//FmfOPtR5S4msqpyPgzxlYwxlYqtr/AGONp9JYDaCWiFiKaBmAMY+wp5vXBbgNwUSVlKMXbj56Od/vxzBYB//exk/C3T5yCrE3oKzhgTP1iyamWeeWXu+ei5m9b0e6sbVmJMkZJz186lyq9QzS1rvpxil6wasA3Kc5f9LhFg5azKZiZqfP8veUKxQHf0m+rXI6HV+7A2l3dQR4hDjcO/UXPi+aDzrpQT/Ga5Bcza+ufk1wP+ouO7/nH943KPsnXxjV/xrzU3SccMAEfOfWAQH/PSZ6/7tkCnp6sNf5lGsiMwlES/9ZN8krK7cPlLrGuRpdHjWv7OvkpSnkXF+TO0ZQ1SZZUzWXgfzm+58+Nf6/g+fPn+PBn34JvX3IkgOg7xd8J8TpH5jKDMuAbF/CqzzsAvMAY6yeiGQDE7EybAMyodQF4jDBjwJv8BVFyGStY8UqVHVD2+HjvQDbIIyJx/hbyxXAWnxztIlJ00nj+0XOJoZ5OYPyjOWxUiD0bufEqOK4X7aPJ6il6/pGYcdsKUtSOkmZIi4ZKt6qUDrnS8wlU08eNiAzei55/VhhMTNL8xQYDiGr+OuRn1FdwMX6k+rlGPH9Vbh/hvhCFhqHoMkwe3YJ/f/NcrN3Zja0dfYoBX30Z9/YUtMa/3MlC/LnLjY1ODuK/SRrw5ccS66poAOVoH/65X3M+Ttmev2+8dfl/kmQfLwOrOtqn6LpwHBZMFu0rOMg7TiTg44BJbYFjGPH8FdE+qrpbC0p6/kS0mIiWKf5dmOK3hwP4DoB/55sUu2mDlInociJaQkRLdu7cqdutJNyIihXOW4glXJRFRvbKsxrPvzUbpl2wKerxqaJ9OOk8f/XEDzHUU9Sq02j+cdmHeXH+mnz+BYcFxv1TZ84Pvs/YFKxlIB9TfImjsk/5mj+f7DZRMG5Tx7RG9PuMTbEBUpXnb1kEi8IlGFsSwik58jPqKzix+RycQokBXznfkDi/hM+V4AOraa6Hs6c7PujOKdf48+cu35Og16lo1JLSOxTdMJJshBTuuHZnV/CZJ+STz5f0bMqFyzZ62SfB+FsUa+CCaB/Xu86RuXDCZb7oxoIIgjTpouevkCmTennVpORZGGNnMcaOUPy7K+l3RDQTwJ0ALmOM8amQmwCIweczAWyRfyuc+xbG2ELG2MLJk+N5PNKienFG5Gx0+sZLVcHkypwNvBfZ+Efj/MWXPpMw4FscgOzDX2Svm8mNf2nPX9Qd4wO+fnoHTW4fL/0w8C8nz4lM5spaFjr81MiylKRbTCTVgK+0D/f8+fX+6YqT8MTVZ4TGv+BEJmnpJs1wMv4gKxDel6QutvyMeGOjeq79xbjs82k/bTUQfcEtosgcDR6yy6O3wl5JKE3p2NXVH5v4xSnXO+bn0ck+KiOfsSx9nL8Tav5yfT7jB48Gx5RDc7kBTHo25TYLvIy6GdFJNleVvI578q/v7ELeiQ/4yno/H78RjxN6/uG+Q8bzHwhENA7A3QCuYYw9wbczxrYC6CSiRX6Uz2UAEhuRaqDqMo9uyQYhcqrIEPml50mX5u0XzZY5QprhyyTPX1d5HTee0EtGH+3j/d62KGK0VSlugajhaJMMNZd94i+f7/n7EpNqTKCU588QNSJpnDjZ6Gz11wrgeV5yvj4vev5Z24pJOLoXKGNRLM4/qVwqaS5NtI/jMoxuzeBTZ0V7SxyLoo1mW2D8M5Gy8UenkiY5fQVH2Xv1zlOm7KPx/LlhUzkYfG1iFQUhjFgXTuu48fz1aTz/cgMFA9lH43MlT/KiWEQT/+uqP7yI9p5CEHnXV3SQd9zYM1FlylVN8koe56geFWn+RHQxgJ8CmAzgbiJ6kTF2DoCPA5gH4MtE9GV/97MZYzsAXAHg1wBGALjX/1dTVF7TqNYM2v0EWqoJQbKHw2dRnnHIfpHt0QFfkgZ89ZWJyz5E+tWHZC+dH85L7Oa9MGLZdS+KuF0r+8iev7DwCJ/VGvle8KDlcopejGoQLwl5Hz6BiTeUvBii5q+UfTSGxntG3mddeKeIqnemytkk78sUC3KI94UQDdPlaTq45x+GP3q/0Rl3AH64svrelmtH+HOXJwxeefo8uAxBMjgRdRikhziBUGeslQEHCWMMnHL9Yy776Dz/JOOfU6Wtlg4jyj79Cs8/MP6KGb65RvP8GWN3MsZmMsZaGGNTfMMPxti1jLE2xtgxwr8d/ndLfNloLmPs40w1D77KqIy/mEY4myF8Q0onK/NvpxyAo2eNCxZR57RmosY/ovknVKaiy9Cv8A4ix9Zo/i5jcH1vXKWTyogvXUz2cTSJ3YQkZCrPX6ygcm9C3Dci+6Qw/vIunX4a3D4hwyMQHbzNWFZwH3UzJsNyh9tlT/TWyxbia/90WGSbaiDTIlL2FsRegipdQFb4kSz7jJI8f34sfpuTZB9ArxOXOwtW5/m3tWRw9XmHKOP8Pc9f/RqrvPr4Pm6ssUnn+SceNkYg+2ijffS/zViW3+NWR78B3jvRkrHQr5F9uEevnOQVeWcawPg3CiovcHQkJ46Fy06cEyQkU/Ghk+fgritPjm23BANsW9GQt6Rn6LjeIh65jBWbrs+RPVOSNH+5cUmSBjixUE/X81JkQyhOSFK9wNHQNHVIKhBtANNIEHLF5++XPNuTX2tfwQleOlX5ZeS5HiJnHTYFJ/sZJTkq2Sdjp4j2YfGGLBrtQ5FGU5Z9wrw2vuav6ckEZdIYyXLHS3kjUo70kLyYS9yxkCmqZEX/70TNv8xr4w35QKJ9wnQnQu9O/r1loTVrh5q/nLKBhxoLx9BN8hoMmsL4q7xAMRsmr5xJXRD5Zf/YW+aG4YVBtE9U9knq0/BJXi0ZGw/9x1twzuHxhkcX5898D0TnLSUhG8nOPi8J1ZgR6lh97nHr5gEACtlHiEpKk9snDUGGR2F8hW/P2FZsGr3uXojXwe+F+JxkQ6WSfXTzN2TZR64z0WgfSfaRjL8sc2VLPFudsS63W83PUk6UjUoP56gkRQD40ElzApl0wJp/mb2aUpO8ktM7xCUb2fP3ktdZ6Ct442g62UekVE+1lgxGnH/dyWXiN13MicMfLH+WsgcPxCvG5889BJ8/95BgfyA+wzcJrvm3ZCyMyNmR8nDksFJed3icv85bSkKukDypmJwpMhxQ5UZIln30E8ei0T6C519B/e6XPGH+f58f7aPKoeKdP3ocXjYitTctb1PJPjapDUVE9lHkiomuZxyVy3jYJ68HMc+/pOwTLw8TZoKnhRdZdiySsIm0UooqYywATBqVg+OnFlGFGvO/Ex2asmWfEpp/wrkywhiYDtvyUlj0FZ3EpVHl3wDpeu3Vpik8f+WAryj7BN97lULVCifVQVGHTvuy8ZTOOYX3ydGld9jc3ov7lm1TeEulH6d8L3Z3+zniJePvJR6jIMpG19C0ZOJesHiOaLRPBZ5/IeoJ8/9df4Y2l8hE4//9dx2NBz59mrJsNoXhmizyfbSMqrTbOs9fDvWMS2XReyGuh8vrIG/w5Vz2WcmBkXuKunDllMtSRMqlO56OUpq/6li8V9tXdEp4/vo6XaqER84YG3GgCiWjffTH4k6BONFLfmdti9Ca8WUfJ542RlVn0szjqBXNa/wjsk/U81eNtid5BboB3yS8xG76ED1AH+f/1b8sx+7ufFzzT+P5S+fjKRpk4+8dz8vfA8QrLn8ZVNP9dVJPGllKR5/G8we85yXOluW8c8FMzNsvujye+KxUjZF8fwYa7eMyFut1yJq/KtqIS1Hh+rVq43DzBxbihvceG5ZJUY+KfjrucuBFTuNIcPi7ofL+VXNIAMH4Fxy15m+n0fyT69NRM8fiyBnh8o88HFU74Ftikpd4DEBj/H3Zp6gY6xDTsou/AQYvwkekKWQflfEfo9D8OaoXKaliBDN8LUnzTyhT0fUWfx7Vqn8EumgfjqyzpjGusge5SyP7AF6F7NOk1eUvgyrFrxjnX+4kLxUT23LY7S9qHoZ6iuWMa/46VCGEYqlimr8uzj9FeodSmr+KGeO9JRWvePNcAOEYgDJXkXANqoafD9YPhHI8f97AO4zBglxHXYwS1v39n48sQsFxscNflawv7wZzViLHTKX5JyPfs6LD8OCK7fi8YmEioFScv+/5F8X3O675t2Rt9BY82Ufl2MmScprcTbWiKTx/5YBvi6j5Rwd8VUY0WfYJf+dGBnz1L57jL4QyTmF0Obp8/hzZKx2I5787wfPP2laQNdPWNJBJnj+TpI+BOv7ifQgG1wXPNJexAo+5pPHnicuEFz0q+0SvU/UIPeMf3y4ndkuKkNLdi5G5DNZdf0EQT3+Uv7rWnu54zn7x+CrvuugMXPMvR4Pm4wOqey9HvZw4dyJOO2hy4Nj0FZ3ILODgmIJDVaqsOuT3oeC4+P0zG/TXkXCuIN2JG33G8u9H5mz05h1tlJOuh1MPz78pjL/s7QJR2UeMThH/FkmWfbzbaBGljq7wFj8vBNkoZS8CUBh/qQyy8S9nEtUX/MFq7lErZR+btNE+vLLqVnYKzlcF2Ud8MYKBQOG45Xj+wbOySOk6pnkJ08g+jkL2EQMP0vaCjp3tGf9lmzti38me/5fOPzTyfdFxU8uQHB5BMyDP3+/Nfvz3z2O9v9i8tyJdvI5wLb4372n+cmNTjWgfedC61NKpiZp/kO5E79zZFmH8yBz29uQ9zV+5lGj0JMGyo4M0qzdy7kE/Yx1QtcBiorBg0NX/W/ViJr2svPIT6fVEGcdl/vq35Xj+kvHXLDiTBBFh3fUX4Iq3zIVtUTDLWQ71BHzNv6DW/LkRVq3pqp3kNUDZJ9J74L0sKQtii/+MdTHcctnEMoo/UenIcoNgpZB9lKGewgvOv9l/4kgcP2eCtryHT/cWb7nsxDmx78RGNmNZ+MhpB0a+L7jle/68YOVo/vz5OIzh9mc34G8vb8Uv//EGAG/gWrVEpqz5y+fTpZaOFLVEdcpaVsSpKjjJKVVKpXTmx+DIdzbjG/893Xk/ZUr8ePFsqf4YltH8a4NK9lEtgiKGesqkkX3EY5SiJ++gJ+/E1r+NlFFODCXVdtnLLeeFBbz70us6GN2SUV5zSyaUfeKev3cuVSphbajnAIx/xqJI463z/LmB0aUZEI8H+KtFpS6DhYLjCH+rPX9xTIAfMwAAGz5JREFUMXnXjT8vOasnADz6udMTz92SsbHu+guU34nGRS37lK/586OU5flz4+8wvOL3UCa0eWnU+wqucmCbv3+9BUcZEWSnCPUsVUL5nhSdUp5/kuwTDyiID/hamDgqh568g1xfUel0ytcTzOMwmn9tKHVj08TjJg74Cvun9bR4iOU4TSpeQJ/PX0epiUAy3GCqvH6Ar3mgifbxX6zpY0fEfpcJoqfKH5COlTFjRROiCeMrQTltCzk7HuqpQtT805pFuYGzNca/Ox+u5aCSfaJx/pV7euKcDVVIZNFlqZ0RThDnPxDjzxhWbN0HIMyF1V9wYoELQBjM0Fdwg6UeRdLk9ill/eX3uOi6QeiyiqRTqWb4qs7HU2u39xSUcnM8ZDrdPI5a0CTGX/1Uuc7NjXfygG8K2QfRQaCk945PrgpkH8XOscRuJV7IpBfltg8fj5+979jINp41VPVyAl6F1IV68pw708YpjL+mBzKQ+t2StSPHUw0ERjT/EtYujUcpM74ti2e/eGYwvqGL9unsC42/KrGbPMmrUiLGX1HHl2/ZFzgjusVeZAai+QfZZl2GLv8e7PGdGy91iF7z7y/qPP/KNf+Mv1Iap1BiAaU0nn+S8bctitznpNXkwt+Evx1smsP4a/KifOviI5HLWJjgt9aHTvNiwqeMiefaSZZ9wsYjyfiIdYvH1+sW4QDiKZ1LpUdI0g1PO2gy3nbU9Mg27vmrBuQAz7joZJ8d+7zyT1fkJdK9sANJWNWSsSKNt63wCLMZSh3tkxV+n7Y0FhH2G9MaWV1L9bJ29YfG38vto/ZmgfLz0qiIev7xA37yf15AwWE4/8ipePzzyfKSXK5yQg/5uR3GgnuwuzvvzWJ3XI3n79W5T93+Ip5btzfB80+Y5FWu5++4wWRBFanSOzgMOzr78JeX4suQ2BZh4ihhLFEZ7SOHb9fPBDet5g8AFxw1DRccNS34+3NnH4yzD5uKB17djn+s2RXZN9HzjwweJmiCRCj6G2OTqxSHj8/wVZ+fp4UutyJxY6Y1/rYo+0SPvdMv/35jWmK/03kxA8ntI84gtihsQMQcRaLnnzT9Xixb5JmVEICCWa9B0jN1qGeX4Pl76R2i31dd9kmx+tOe7n6MG5mLZBBNIjD+5Xj+VmgYeX3Z050PBsCTPH+OzvNPaoNKav4WRRqIosuCyYIqkrzvcBUuF//2myV4eVM8+opH+3DSaP6V5LuqlObw/FN6MRnbwoL9xysrXNIzEh/o+0/YX7ufKNvwaeLjE7rjLSVCPYOy+f+Xu+QdN/o62SeXCaN95GPzwej9Ris8f675S9sH0rVtzdrB8xO9JtHw5QTjX2p8U4wiSdsT4cXmvQYxk6tI1PNnsX1UA76VEB0IVx9PlV00Cd4fKmcBcW7AeOQO4Bl/3mtU1S9Z0oxF+wSyT5Lnn1xG+f3pLyZ7/kmHCzV/hu37+tT7WBSJIlT1xGONXB2ifDhNYfzLNTqq1jipoole3Ffedhhu/sAC5X6qF3R8guavy+2jK1u51xl4/ppFTURZQT72De89Ft99x1Gx9Q2SyjEQe9eSsYQInXC7ZYUpHbzcPqFnloQYLXTO4VOw6MAJuOrMg5T78ssIZnALue7lOpK1KW785X3EUM8qvPNplvAEyvMuB1IubuT29XmDvK1ZC7u788HscF20j6iPDyjap0RZWzJRzX9Pdz5R8086V07Q/OXkiOLvVdmCRWKav/H8hxbleD2AHIdOsXkD73jTTLz3+FmxB52zrVj3NzgOxeUqXUWp3PPXyz4c+dhTxrTi3cfFV3UC9BNWBhbtY2tzzPPY/qxtBS9aCdsfCfUc3ZrF7ZefiNkT4w2YeL4guVpgkOKJ3Ua1ZKLG34173JYlNijJ5UxDdMB34B6yinLmB/BGbp+/pvOs8SORL7rBrGRdz1Kc3S5XGd1C8iKlrkqu18s2d0QSs8kkruTFcy5pBrABr35npR5pfB9Z86+f8W8Kzb9cym2N5f3lX//g3UcDAO55ZVtk+7iRWe2L2Zq1Y9+R5v0eSHgeEHqOqkk4QLLnn4TuJRqQ5p8NB3zjxtQ3yv6A7z8vmo2Lj52ZeLw0WvJfP34KWrIWLvqvJ5B3wvMG95ni0T5tLRls6+jD35dvw8FTRys9f8tP7OU68e8GQqkBX045z24gDQU/Pvf8Z00YidU7urCl3ZNHdM6FuJqebJRn+jmOkuLy03j+Is+8sSdx/7TGXzeGqAuHFtGNbQDAodPGYNGB+gl/1cYYfwXlev5pw0bkylHO7F4gyfMnAPGc6KXgmqiu9xEdUCxLOPaQnKyBGJaDpozGTj8JWGyCjP9nzrZARLj2oiNLHo97yEmD40fOHBs5X7gGgO+N2vFon1EtGRRdhn//3VJ88MQ5cFn8eRB5xyo4rCqaf9rnU57m71PG/IDQ+Hue/2xfCtzS3gtAv3D7aQdNxkv+wGmfpMXPnTwKALB+T3ea0ioR36FJo1qwq6sf5x85NeaEcZLuE7/X+QTZJ8w466W4VkUZ6hLYAcC9nzpVX4AaYGQfBdXwytIcV5zgJb9rU5XhpslaermDRyWjfYTKW8494fHwnzk7qqWX2zO58vS5+MK5h2jD/gaSCz04VoqiBBIR8cE+Hr1ixQwFj6ZhDOjuLyoTu1lEkTkhlRJJ7Cbdm1s+sAAz/DkY5Tgz/DGXioCKlCOQfTzPn3vtWzo846+rX1eddRA+dNIcAHEPf95+nvF/Y6fe+KfS/P3PY0Zk/OOO1u6fVD+5o8SXXk36fZisLb5fmhz/g4Xx/BXUarKdfFxVRs93L5yJT5wxXznrVnZWLzrGi9sfSHgekC7ah1NOryJrW8qUBOXKPmceOgU5YYavfP+CpFhlPDBVqKd+Xytyno17egAAcya2xTx3McFdb8FR5vMnCo9VDQdDLIPs+U8Z0xosWFTOuYJO24A8/1D2ARDIPjrP37YIiw6ciF8/uS5m/Pef2AYgnrZcVVYdrVkbB0xqw9L1e4O6N2t8fFIiJ1H2ETx/3fWIRr+voJaHdFFN9cAYfwVlv5hS/Zw53qv8Jx44MbqbtJ8YE8zXcz3toMnKCBq5XFe8ZW6QmZOH5w00qkkX7aNbkWug6MYsdMi5zuMTZPjLlr5s5RjE0PP3/uZ2aK7vlYqIjXVv3lHm87eIAotV7XdeHmS3LQrGcsqL9vH2HZDx743KPlvbkz1/IKz3cghmLmPhWxcfiaNmjlX9LBWtWQvfvPAInH/kVDy4YgdW7+jCNEU6Ek5SD4nXsf6i3vjz582NfppQz1qpDGkwxl9BpYZu3n6j8MTVZyhnvwJeeOfenkKQ/wQArj7vUEwbOwLnHTFN+Rsg+hKLXsVAPX/etU8j+1Qj62DZA+lBlI1vhDWev64broJ3/5Mm+3CC1aSkcqu8x5PnTsIJB0zAn57f7Hv+8XpEwrGq/c7Lkp9F4azncqrF199+OEbmbJwyf1L6c0ue/6RRLWjJWCU1fyBcDEi1Ytr7TpideN5S7VNLxsaInI0zDpmC4+ZMwOHTx+LkeRO1+yfdJyIviq+/6CRo/qVlH91M5npQkcBBRO8iouVE5BLRQmH78UT0ov/vJSK6WPhuARG9QkRriOgGqsbIVwp+cukx+PW/HJdq37JbY8XuM8aN0A7q/dPRnlwzUzAio1oyuPL0eanjmsUKyDeXPVCtOJZIywCjfXSUewx5Zq3ceAxE8x/jL5DeI4Rl6hDDQiPbFefLZSxcduIcjGnNoMfPUR+LTqJwZnC1q72c1M8WQo7LqRezJozEz973pkRvXYY/p7W+Pj+qJYOJbTls6UiO9gEEzz9FYyxTKn26GMU2ujWL950wO/G+l3JOWjKWspEKfi9NTFOnd5Aa6QaWfZYBuATAzYrtCxljRSKaBuAlIvorY6wI4CYAlwN4GsA9AM4FcG+F5SjJhcfMSL1vrR4Ir6qzJ4zE4s+cFshDaSGt5z+w8vKuve7nSXH+A6HcYsrJvXSREuUY/9G+8e9OYfzFtBIAcP9VpynzwZ88byLe5qcJGZmzsWNfP4jiz0XcVu3ufvzeCPMUauxfcU93xdZ9mDa2Fa1ZC+MF45/k+bf5nn9Snn0dpWZz6+LxdZScMewbf91cAXlVLvUkr6ETY1OR8WeMrQDiN40x1iP82Qrf7vkNwRjG2FP+37cBuAiDYPzLoVaz7vr8vCdtLZnEqIM0iN767z9yAu5YsgmjU+ZvSYsqoVollC/7eP/rFvbgf5aj+XPZpztf2thkpFmmB09VP7Pvv+vowLsd4a/hOiJrx+d/CJ5/tf0L2ahYFE44qrVzKTYunz/3YBBRZABcTrMgwvdLSrWso9RENF0gg45S9ylnW+gvutr8Ufx58/ueJs6/ntRM8yeiEwD8EsD+AD7g9wJmANgk7LYJgNYlJ6LL4fUSMHt2sv5XTWrVOPM0yBNTptdNQjT+R80cF6z1Wg781dFVx5zgOZU7h0DFgGUfjQcrD7ClYUwZnj9vdEp5hGK5RuQ82SeXsWJjFOKxqu1fxFYbIwqWjay1tCA+Vx7EIEo9unkkQBgiOyDZp4TxL6deAKXrZ0vWRr7oRhZ0EeH3mTfEqjj/pF7QYFOyJES0mIiWKf5dmPQ7xtgzjLHDARwH4BoiaoXazmifIGPsFsbYQsbYwsmTJ5cqatWo9TDExFHxTJjlUtXFHzTXG4nzr8Lpyr2v4UIX6t8Fsk9ZA76e8de9wNHz+z2OMoy/t4B3UTnDVzxm7WUfGjzZRzg3N7jc4HspD/Tnb8lY+NBJc3D7vy8q+7ylIpLKrW+l9s/ZXPbxGqpTNYPi/HpVRzvMX5ZzKFDS82eMnVXJCRhjK4ioG8AR8Dx9cf79TADxxNh1ptbJliaNqq7nP1ACzT/FOarh+ZeLFcg+ft4e6W0fSJz/mNb0nV1Z8y+1HxDKPqpQTyD0/Ko/4CvJPkKemVrXZ/E6eUPMs3aOVKQpESEifO3thw/ovGWvT1yCUtWIR/sUHYaT5k7Eb//1BMy5+u7ge14c1ZKPnIX7D176hlLU5I0mogOIKON/3h/AwQDWMca2AugkokV+lM9lAO6qRRkqodaz7qrh+ZfbpVVx1qH7AQCOna2WjMRz1GMmIj/nZP9+8TQP8vflGDc+4JsG3uiUXEEtIvvYcJm3PKHqZ3wQstp3Uy6jTaHHXet4OnlVNSD0/OXUzdXELRGwUC6leki5jIW846LgMs3ArVcgft8LCilLN25UDyrS/P0Qzp8CmAzgbiJ6kTF2DoBTAFxNRAUALoCPMcb46ihXAPg1gBHwBnqH1GAvEH2R7v7kKdr83QOlrQovRDkerI4zD52C1dedp/Wcc8IapPUYqOJGdX8/6+benkLke/6cSi3dKFJOjymMky8h+wiH5AOY3f3FoHxvPmgyHl21E0A4CFnzQVgLwoDv4Gn+3PBxzX9kTY2/99wtorLqwDNfPBNX/G4pnt/QHtleUvP3o32KjqtcL5vf70+cMR9L1j2rlHhsi/DiV96KXV392NbRH/t+MKk02udOAHcqtv8WwG81v1kCTwIasuw3OvTMD58+FodPH/gsQxXV6PKrVtAaCEmSCV8UHaiP58+NJ5/qH/veL9JAuv9pIkHSTpKSZR8A6MoXA6N7y2UL0N3v57b3v6/5ICxRMGBdbXkkdi6F5h9EP+VqN4+UBcYfKCdQdMqYVlx93qF4981PRbarFiYSyWUsPPn6bgDROToA8OP3HBPU05PnTcKab52vPc64kTmMG5mrOOKvUobO0PMQ4ogZ5Rn7yX5jMVuTlqEW7KdI/FZt0qYMrhXc89eNkRwzy5OrVDmSkvjbJ07BI589veR+XKIp1fBZkuwDePov/1lLJly4pFaav4xtUWCI0wxuV3QuUfOXZJ9ywy3Lga/dwDOAlsPxB0yI5Z+aNUGf+gGIyqCy03TRsennEQ0VTHoHBaPKjJc//eD98KsPHacd/efcetnCqr2I1Y7pV1HtGb7lwr1jnaH84vmH4qJjZuDAMl/+tI17LqWhVnn+8nYO94hrfTdJ8PxV2nM1EVNLhAO+/r2r4Xl5j2bm+JH485Un46t3Lccflmwc8PFmlZh0KTpDVY22qxPG+Gt4z8JZ2FqG1n/6IfuV3Oesw6ZUUqQIg5EVQxycGqQsHBHE3sYDnz4tNsiWtS0cPav8+Q1pyaWMlhG/F5fxU90zbvyrpcNfftqB+OtL8YA5cVWppMyY1SDq+XufeSNYy3rDZ8gfN2c8WrN20NiNyNr4z7cdWvbxdAkVOUVhZi+vm/+8aHbDNgTG+Gv4zjuPqncR6k5r1sbnzjkYi1dsr8v5Rc95/pTB10dbUg7Oivq9KEGosqWGsk8VCgiv9/PF8+OGzhZm+BYS1q2tBuKAt6z515LDpo/BI599SxAQwK/3Ayfuj/efsH+qY9z7qVNx3k8eByCsp61BTMTIHZE0CwgNVYzxNyRy5enzcOXp8+py7nqmuwVCQ1bO4KwYLKBKR8w18MEwyEkhh9VEqfnnBkfemjMpDAZImlyl49BpY3D75YuwcltnyV5Ku2D8y0kpMlQxxr/B+OWHFmLqmOSBqeFCPVc5AkTPP305RAOyYP/xse95b2AguWzKwaZwhm+tGxpxAqA84DuYDTg/d7lS06IDJ2LRgfpUz5x9oudfh0mP1abxr6DJOOOQKUNqingt4EtY1jsHFg91LTdS8j0LZwGIhwMCYYMir1lbbWyLgsHXWmv+oh2U4/xr7voLZOzqSmoy+4aZ52+Mv2HI8aePnYSfve/Yugwyi3BD7bjlec7fvuRIrLnuPGX5efjoQBKZlQMRITdYso/QSsspqwfzCeZqPK/h2ouF6UmNb/uN7GMYeswYNyJYfLye5AYYLWNZBEtjHVoHyfMHMGiyT9oFiGoN9/wdTb79SrnwmBnYsa8f192zAoVibXtTg4Hx/A0GDTyuW5e/fSBwOaRvAIuXlMuJcz0d+9Lja5sOXRUKy2WRMWXkUqoUHn5ZTqqHcuF1otYN6mBgPH9DzXn0c2+JhMk1Ci2B8a+eMeHHrNWA7+jWDDr7vLUKpo8bEZvFWgtUnv+bZo/HZ88+CO+tccMjwo1/qeUdK2GwwmcHA2P8DTVHl5tnqJOrwYBp6PnXxnjcd9VpWLW9sybH1qEa27AswsfPmD+o5bAHIZ0FrxNJa/k2Csb4GwwauGZeTdnnnMOn4sJjpuPq8w6p2jFFhsp4ST0IZJ+aev7eOfLG8zcYhi9Bbpwqyj6tWRs/ufTYqh3PEMLlp5p6/sNI9jEDvgaDBu7lFcsM9TTUBz7wPDiav4n2MRiGLaHs0/gvejOQsWvv+R/k55g689DSiRyHOkb2MRg0hLKP8fwbAT6xrJahnrMnjsTyr59T0xXKBgvj+RsMGpIW4gZqu1CJoXyCAd8a99TaWjJ1n31eDYznbzBo4MZEF+3zzDVnDcpkLUM6BrKmczNjjL/BoKHU4N7YkVmMxeDNYDUkMxihnsMJ0281GDRM9+PlLzp2ep1LYkjDYIR6DieM528waJjQlsPKa8+NLNxtGLrYg5DeYThRUa0moncR0XIicolooeL72UTURUSfFbYtIKJXiGgNEd1Aw2HkxDBsacnYw2Jwr9bc/IEFuOvKk+tahtDzN9FZaajUpVkG4BIAj2m+/xGAe6VtNwG4HMB8/9+5FZbBYDDUmXMOn4qjZ42raxnCSV51LUbDUJHxZ4ytYIytVH1HRBcBWAtgubBtGoAxjLGnGGMMwG0ALqqkDAaDwQCESdeyGdNTS0NNxEwiagPwBQBfl76aAWCT8Pcmf5vuOJcT0RIiWrJz587qF9RgMAwbjpk1Dp88Yx5+8K5j6l2UhqDkgC8RLQYwVfHVlxhjd2l+9nUAP2KMdUl6qapJ1o7OMMZuAXALACxcuNCM4hgMBi1EhM+cfXC9i9EwlDT+jLGzBnDcEwC8k4i+C2AcAJeI+gD8CcBMYb+ZALYM4PgGg8FgqICahHoyxk7ln4noawC6GGM/8//uJKJFAJ4BcBmAn9aiDAaDwWDQU2mo58VEtAnAiQDuJqL7U/zsCgC3AlgD4HXEo4EMBoPBUGMq8vwZY3cCuLPEPl+T/l4C4IhKzmswGAyGyjBTFw0Gg6EJMcbfYDAYmhBj/A0Gg6EJMcbfYDAYmhBiDbLwARHtBLB+gD+fBGBXFYvTyJh7EcXcjxBzL6IMl/uxP2NssryxYYx/JRDREsZYLOtoM2LuRRRzP0LMvYgy3O+HkX0MBoOhCTHG32AwGJqQZjH+t9S7AEMIcy+imPsRYu5FlGF9P5pC8zcYDAZDlGbx/A0Gg8EgYIy/wWAwNCHD2vgT0blEtNJfLP7qepdnMCCiXxLRDiJaJmybQEQPENFq///xwnfX+PdnJRGdU59S1wYimkVEDxPRCiJaTkSf8rc36/1oJaJniegl/3583d/elPcDAIjIJqIXiOhv/t/Ncy8YY8PyHwAbXsroAwHkALwE4LB6l2sQrvs0AG8CsEzY9l0AV/ufrwbwHf/zYf59aQFwgH+/7HpfQxXvxTQAb/I/jwawyr/mZr0fBGCU/zkLb02NRc16P/xr/AyA3wP4m/9309yL4ez5Hw9gDWNsLWMsD+B2ABfWuUw1hzH2GIA90uYLAfzG//wbABcJ229njPUzxt6At8bC8YNS0EGAMbaVMfa8/7kTwAp4a0Y36/1gjLEu/8+s/4+hSe8HEc0EcAG89UU4TXMvhrPxnwFgo/B34mLxw5wpjLGtgGcQAeznb2+ae0REcwAcC8/bbdr74cscLwLYAeABxlgz348fA/g8AFfY1jT3Yjgb/7IWi29SmuIeEdEoeOtHX8UY25e0q2LbsLofjDGHMXYMvPWzjyeipIWVhu39IKK3AdjBGFua9ieKbQ19L4az8d8EYJbwdzMvFr+diKYBgP//Dn/7sL9HRJSFZ/j/mzH2f/7mpr0fHMZYO4BHAJyL5rwfJwN4OxGtgycJn0FEv0MT3YvhbPyfAzCfiA4gohyASwH8pc5lqhd/AfBB//MHAdwlbL+UiFqI6AAA8wE8W4fy1QQiIgC/ALCCMfZD4atmvR+TiWic/3kEgLMAvIYmvB+MsWsYYzMZY3Pg2YaHGGP/jGa6F/Ueca7lPwDnw4vweB3Al+pdnkG65v8BsBVAAZ638q8AJgJ4EMBq//8Jwv5f8u/PSgDn1bv8Vb4Xp8Drmr8M4EX/3/lNfD+OAvCCfz+WAfiKv70p74dwjW9BGO3TNPfCpHcwGAyGJmQ4yz4Gg8Fg0GCMv8FgMDQhxvgbDAZDE2KMv8FgMDQhxvgbDAZDE2KMv8FgMDQhxvgbDAZDE/L/AZR2YQbcbWQMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------tool_keshid_oomadam_biroon--------\n",
      "Episode 454 reward: -100.1\n",
      "454 Average episode reward: -118.70449597028208\n",
      "[-119.0677961272409, -117.82109943336958, -119.97185042059522, -129.04493754116115, -106.79692437998017, -109.52154627474928, -119.4134536510728, -110.81818449837219, -112.27119873316305, -120.43941081583957, -124.28055715107655, -125.62799552455014, -115.4963088405492, -114.28023085952259, -113.4810453188152, -121.42528764068041, -112.61377966021645, -125.75089372724804, -114.758949489912, -111.8784823816146, -131.61199838972237, -132.65146059060075, -116.21426548718493, -114.81891208341126, -131.24322629310646, -106.96606744091002, -106.26093387706368, -121.46817186340184, -120.73732285054886, -115.2570682357141, -118.5305018094357, -117.19855743254996, -113.31388620230796, -122.12680626933319, -116.48969685874879, -116.51316402035727, -112.95760683807427, -114.88881199102123, -132.15424888894265, -114.79937643208974, -115.32900528060323, -108.55926776577708, -126.31713754210547, -115.45532686780132, -128.58628797181206, -114.3936165203636, -111.7157794515809, -114.23155481968216, -109.23885606079762, -126.88643483608804, -116.70424620118203, -114.58839109637266, -132.23233330035043, -129.70186211012125, -114.64630515141981, -128.621898210331, -129.24437573520723, -126.15672535984135, -123.30571259085079, -115.78607993126694, -106.6636795034471, -121.87380743003567, -108.76889037116224, -128.70293485015634, -109.93985222350948, -128.01513710427136, -117.03484886380065, -127.93702706884729, -121.66358157288678, -115.94470458512724, -113.76248247806113, -109.99570969199661, -117.77274081482716, -114.80453049636594, -113.83565994567437, -112.77729015448145, -111.20023683856505, -133.4756856985988, -131.29303227870315, -123.07544471221972, -128.1946207948181, -113.20236793663989, -114.391512740206, -113.65305284491818, -118.9796976902818, -129.71367753450676, -116.07845295652778, -114.85480474484325, -115.90654389485088, -116.30932613276602, -115.8103309386342, -111.25616152467815, -114.56472101007498, -117.21043433546316, -118.0758955953931, -111.13623523753066, -118.15085143604858, -116.23722794049226, -125.20748915874432, -114.08476723510218, -117.24206658112928, -115.18472661405322, -124.04118588771708, -113.47787707612147, -114.16597590712773, -124.58858207199795, -131.10157750104636, -125.04890676615263, -121.79203130465113, -110.74968025676486, -110.35851697458584, -111.91804559893609, -114.13542629682804, -111.97115240470733, -111.87099596090694, -112.68780812413863, -113.62372956619802, -124.43978257288006, -132.51737470942786, -132.96797737844355, -118.73980651848869, -120.09695245216506, -117.88846954827908, -118.57664766454404, -117.13098474794786, -118.58681656953087, -116.93734254258345, -115.78482844758035, -126.45396949669747, -124.58029521599713, -119.70747955304714, -116.79675538864035, -116.8139113833316, -114.8822267880827, -114.02821399959006, -116.84783035774424, -116.46341822076083, -117.41261085171546, -114.88323462893176, -127.87384046927933, -113.79536397782405, -115.43229575487491, -113.59750747790837, -114.26551578607219, -135.03786254536072, -114.35933632082393, -114.11987037107203, -113.86520416491236, -113.82510488615854, -114.70020700622617, -114.04797946709584, -115.41989832273146, -114.39893294302873, -113.63090661816105, -114.85394560721696, -114.01386323825153, -117.76404553768808, -116.89870986207221, -116.24278237868168, -116.4597744626657, -117.51174989221376, -116.90346542502418, -134.10903094614739, -116.51129815783591, -127.68526683025146, -123.43780092217423, -120.8810883799521, -119.44360035239421, -130.91150884925622, -132.47350337930988, -116.29630417437846, -114.4390370250422, -120.24704067413512, -113.36635067560813, -110.39547642539645, -110.10151341299684, -125.82616713113906, -132.13216742128245, -122.89882753081221, -111.83352135484192, -116.42443789378179, -119.66764964733986, -127.16221374099663, -112.29833322622316, -112.32324595288763, -113.03871827932343, -110.0777278977423, -113.1624403534243, -122.63605289641058, -112.95519869376955, -113.99097012975284, -113.5706352232453, -100.1, -116.98792483766923, -114.90964621664315, -115.59493737418606, -128.34533723236746, -131.83299694021474, -115.08785849936798, -116.55008855021036, -114.06845267334073, -126.5364569715634, -113.26037735423262, -113.8747401493763, -113.16393088390362, -114.37840735072157, -121.3605372895653, -114.34575575605119, -117.73111657793305, -127.06424817751747, -115.71679743132941, -117.97415644290983, -130.99965090952466, -138.4472465558157, -115.76781630951861, -118.90882441534217, -125.07030024793738, -117.6060040784776, -129.2986501632771, -127.92458821883926, -112.96525533199916, -117.23517295421696, -117.3839310759299, -118.23698271438586, -137.54012508304112, -118.69710052523982, -129.38474650329547, -116.78127240120467, -124.68228650605721, -128.67857484128652, -128.13005120453448, -127.54731030181988, -132.73212969232986, -133.96908019347472, -133.03183427933578, -109.7496078919459, -120.44774697282952, -111.14034640228437, -112.03136404273005, -131.45288126226365, -100.1, -98.44564846153953, -113.29075157051227, -130.4404584476155, -135.77947873979804, -103.58099427177123, -110.06462065000139, -110.54162778575123, -119.92013854350895, -124.37725680228374, -120.23412628108169, -117.72067185134611, -111.05259886906934, -119.47854849644109, -115.21948716161207, -119.69739495969012, -123.40434307392454, -116.10585369854417, -116.2149521882368, -108.6063997774863, -107.54996377088766, -123.4039268020828, -124.36823787143621, -114.74229782654443, -117.63942549807196, -118.42202860494467, -118.3477053285582, -115.21861282476043, -114.62033348396835, -111.69633743078796, -122.78683922287684, -111.58257355743007, -124.55530159321151, -132.65542524471775, -120.62097257201503, -117.76240322148192, -96.77808350738869, -123.95496786415242, -111.47795443789262, -135.37461636603922, -116.22764507808834, -127.61602326372412, -125.685319455501, -128.04624148312706, -134.88958326288505, -112.47454805767211, -125.38863957150217, -110.62432002095674, -110.55056229787814, -111.62901938126964, -110.27766923862086, -100.88806255115671, -116.39190012662245, -116.76730120002361, -114.55955847457312, -115.61456416540892, -115.35472398367196, -114.5805003431133, -116.4805031275319, -118.53849535718426, -115.73759882155989, -116.66037623109754, -118.01470817304737, -128.75825038849354, -115.51301599514392, -116.05694056314674, -116.73056471682312, -116.52195195764986, -117.04732526013159, -115.96561727539975, -117.89988700633633, -117.3406493765519, -121.05556052009871, -116.0292704576672, -114.720004735148, -113.70451553331402, -114.18564007879974, -112.83080647899826, -113.16400067355532, -111.54640249158706, -110.7902867106549, -110.49560168565472, -122.29645462006134, -138.91469860402668, -129.58901779103246, -129.47625956595877, -125.0365867055356, -124.26744583871861, -127.0254627771871, -129.5133992247701, -135.09326507018307, -130.01456457918255, -123.56212655024986, -111.88451910060276, -112.94498385561982, -116.7613630664009, -116.85047340226214, -117.35345535394225, -123.27273711515932, -112.50489727495673, -121.85569033265124, -120.56908986362254, -126.41959010101584, -127.65550702113467, -125.79721100471936, -130.35348406909912, -116.62809855076043, -114.14472758376743, -116.51721355937605, -116.40271801670688, -116.84933919389319, -109.07825829534606, -112.99008687752529, -127.04253830910379, -128.39303310695456, -113.75867636763496, -113.91647467549096, -115.99276972767072, -115.84095194419604, -116.30689128166703, -117.40742105588406, -115.26606810306554, -115.71344809154134, -116.30407411499318, -116.4771139239352, -100.1, -76.78895285163374, -132.74451700090668, -114.60652740924138, -114.87684528506796, -132.06446469900231, -114.19684121188479, -129.80419407586996, -139.89499053304354, -110.19813142068432, -132.5886477139756, -126.14839825173978, -114.42058606419006, -122.60144896680052, -114.59821430057723, -128.33142627529625, -115.36119580991777, -126.3794820104998, -128.67949598755888, -127.28428714003292, -127.19961085082299, -123.54523011209443, -131.18268280943332, -111.98236924418075, -131.70108586300262, -110.3237015066684, -132.77695313342065, -111.860187755797, -133.19897074150268, -131.51706733480313, -109.26953333806283, -106.48105325519448, -110.51568496725581, -107.66163490800145, -109.58507575866392, -110.4845666509024, -108.99452398393616, -113.87715518641033, -113.70156942279739, -113.2738291511971, -115.88385468724893, -116.1363587684482, -126.69669023092021, -134.23418817843094, -131.93957074013596, -136.85932630994907, -125.94497756030664, -130.43418353160416, -128.59571182691053, -117.12156966860405, -132.62452147741138, -120.9163606823306, -131.5491796373906, -116.9040846292093, -116.70732160792748, -117.7049540090185, -123.78924764346873, -126.47095498028969, -131.36619384158917, -121.98038375732966, -114.15387051178456, -113.48761902380048, -112.33695253107562, -113.07724440229752, -115.59008660264443, -119.40129222896579, -117.99222238125923, -117.23009310151345, -130.19665000172873, -131.12770769578188, -115.2823094571869, -131.22397765495654, -115.57327504126278, -116.66717303264073, -100.1, -115.60495000706928, -116.15619707263906, -116.94590643232797, -127.22191807182632, -116.35058756631682, -118.63335220923854, -118.96902603008054, -100.1, -100.1, -100.1, -109.54695851907682, -100.1, -100.1]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('actions.npy', replay.actions)    # .npy extension is added if not given\n",
    "np.save('current_states.npy', replay.current_states)    # .npy extension is added if not given\n",
    "np.save('next_states.npy', replay.next_states)    # .npy extension is added if not given\n",
    "np.save('ends.npy', replay.ends)    # .npy extension is added if not given\n",
    "np.save('rewards.npy', replay.rewards)    # .npy extension is added if not given\n",
    "np.save('episode_rewards.npy',np.array(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(replay.rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay.current_states = replay.current_states[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2431"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replay.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(replay.actions))    # .npy extension is added if not given\n",
    "print(len(replay.current_states))    # .npy extension is added if not given\n",
    "print(len(replay.next_states))    # .npy extension is added if not given\n",
    "print(len(replay.ends))    # .npy extension is added if not given\n",
    "print(len(replay.rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SAC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
